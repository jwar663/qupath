


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html id="htmlId">
<head>
  <title>Coverage Report :: OpenCVClassifiers</title>
  <style type="text/css">
    @import "../../.css/coverage.css";
  </style>
</head>

<body>
<div class="header"></div>

<div class="content">
<div class="breadCrumbs">
    [ <a href="../../index.html">all classes</a> ]
    [ <a href="../index.html">qupath.opencv.ml</a> ]
</div>

<h1>Coverage Summary for Class: OpenCVClassifiers (qupath.opencv.ml)</h1>

<table class="coverageStats">

<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
<tr>
  <td class="name">OpenCVClassifiers</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 6)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 60)
  </span>
</td>
</tr>
  <tr>
    <td class="name">OpenCVClassifiers$1</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 1)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 3)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">OpenCVClassifiers$AbstractOpenCVClassifierML</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 17)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 91)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">OpenCVClassifiers$AbstractTreeClassifier</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 4)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 17)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">OpenCVClassifiers$ANNClassifierCV</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 11)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 99)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">OpenCVClassifiers$ANNClassifierCV$ActivationFunction</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 2)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 9)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">OpenCVClassifiers$ANNClassifierCV$TrainingMethod</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 2)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 7)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">OpenCVClassifiers$BoostClassifier</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 6)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 15)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">OpenCVClassifiers$DefaultOpenCVStatModel</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 4)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 4)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">OpenCVClassifiers$DTreesClassifier</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 4)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 4)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">OpenCVClassifiers$EMClusterer</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 6)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 9)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">OpenCVClassifiers$KNearestClassifierCV</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 6)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 11)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">OpenCVClassifiers$LogisticRegressionClassifier</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 7)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 28)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">OpenCVClassifiers$LogisticRegressionClassifier$Regularization</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 3)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 10)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">OpenCVClassifiers$MulticlassANNClassifierCV</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 3)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 3)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">OpenCVClassifiers$NormalBayesClassifierCV</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 6)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 11)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">OpenCVClassifiers$OpenCVClassifierTypeAdapter</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 3)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 4)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">OpenCVClassifiers$OpenCVStatModel</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 2)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 2)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">OpenCVClassifiers$RTreesClassifier</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 10)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 81)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">OpenCVClassifiers$SVMClassifierCV</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 6)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 7)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">OpenCVClassifiers$SVMSGDClassifierCV</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 6)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 7)
  </span>
</td>
  </tr>
<tr>
  <td class="name"><strong>total</strong></td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 115)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 482)
  </span>
</td>
</tr>
</table>

<br/>
<br/>


<div class="sourceCode"><i>1</i>&nbsp;/*-
<i>2</i>&nbsp; * #%L
<i>3</i>&nbsp; * This file is part of QuPath.
<i>4</i>&nbsp; * %%
<i>5</i>&nbsp; * Copyright (C) 2018 - 2020 QuPath developers, The University of Edinburgh
<i>6</i>&nbsp; * %%
<i>7</i>&nbsp; * QuPath is free software: you can redistribute it and/or modify
<i>8</i>&nbsp; * it under the terms of the GNU General Public License as
<i>9</i>&nbsp; * published by the Free Software Foundation, either version 3 of the
<i>10</i>&nbsp; * License, or (at your option) any later version.
<i>11</i>&nbsp; * 
<i>12</i>&nbsp; * QuPath is distributed in the hope that it will be useful,
<i>13</i>&nbsp; * but WITHOUT ANY WARRANTY; without even the implied warranty of
<i>14</i>&nbsp; * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
<i>15</i>&nbsp; * GNU General Public License for more details.
<i>16</i>&nbsp; * 
<i>17</i>&nbsp; * You should have received a copy of the GNU General Public License 
<i>18</i>&nbsp; * along with QuPath.  If not, see &lt;https://www.gnu.org/licenses/&gt;.
<i>19</i>&nbsp; * #L%
<i>20</i>&nbsp; */
<i>21</i>&nbsp;
<i>22</i>&nbsp;package qupath.opencv.ml;
<i>23</i>&nbsp;
<i>24</i>&nbsp;import java.io.IOException;
<i>25</i>&nbsp;import java.nio.IntBuffer;
<i>26</i>&nbsp;import java.util.Arrays;
<i>27</i>&nbsp;import java.util.Locale;
<i>28</i>&nbsp;import java.util.concurrent.locks.ReentrantReadWriteLock;
<i>29</i>&nbsp;
<i>30</i>&nbsp;import org.bytedeco.opencv.global.opencv_core;
<i>31</i>&nbsp;import org.bytedeco.opencv.global.opencv_ml;
<i>32</i>&nbsp;import org.bytedeco.opencv.opencv_core.*;
<i>33</i>&nbsp;import org.bytedeco.opencv.opencv_ml.*;
<i>34</i>&nbsp;import org.bytedeco.javacpp.indexer.DoubleIndexer;
<i>35</i>&nbsp;import org.bytedeco.javacpp.indexer.FloatIndexer;
<i>36</i>&nbsp;import org.bytedeco.javacpp.indexer.IntIndexer;
<i>37</i>&nbsp;import org.slf4j.Logger;
<i>38</i>&nbsp;import org.slf4j.LoggerFactory;
<i>39</i>&nbsp;
<i>40</i>&nbsp;import com.google.gson.TypeAdapter;
<i>41</i>&nbsp;import com.google.gson.annotations.JsonAdapter;
<i>42</i>&nbsp;import com.google.gson.stream.JsonReader;
<i>43</i>&nbsp;import com.google.gson.stream.JsonWriter;
<i>44</i>&nbsp;
<i>45</i>&nbsp;import qupath.lib.common.GeneralTools;
<i>46</i>&nbsp;import qupath.lib.io.GsonTools;
<i>47</i>&nbsp;import qupath.lib.io.OpenCVTypeAdapters;
<i>48</i>&nbsp;import qupath.lib.plugins.parameters.ParameterList;
<i>49</i>&nbsp;
<i>50</i>&nbsp;/**
<i>51</i>&nbsp; * QuPath wrappers for OpenCV classifiers, which are instances of StatModel.
<i>52</i>&nbsp; * There are two main reasons to use these wrappers rather than StatModel directly:
<i>53</i>&nbsp; * &lt;ol&gt;
<i>54</i>&nbsp; *   &lt;li&gt;Improved API consistency when exchanging between classifiers. For example, some require 
<i>55</i>&nbsp; *   training data to be in a specified form (labels or one-hot encoding).&lt;/li&gt;
<i>56</i>&nbsp; *   &lt;li&gt;Easier serialization to JSON along with other QuPath objects via {@link GsonTools}.&lt;/li&gt;
<i>57</i>&nbsp; * &lt;/ol&gt;
<i>58</i>&nbsp; * 
<i>59</i>&nbsp; * @author Pete Bankhead
<i>60</i>&nbsp; *
<i>61</i>&nbsp; */
<b class="nc"><i>62</i>&nbsp;public class OpenCVClassifiers {</b>
<i>63</i>&nbsp;	
<b class="nc"><i>64</i>&nbsp;	private static final Logger logger = LoggerFactory.getLogger(OpenCVClassifiers.class);</b>
<i>65</i>&nbsp;	
<i>66</i>&nbsp;	/**
<i>67</i>&nbsp;	 * Create an {@link OpenCVStatModel} for a specific class of {@link StatModel}.
<i>68</i>&nbsp;	 * @param cls
<i>69</i>&nbsp;	 * @return
<i>70</i>&nbsp;	 */
<i>71</i>&nbsp;	public static OpenCVStatModel createStatModel(Class&lt;? extends StatModel&gt; cls) {		
<b class="nc"><i>72</i>&nbsp;		if (RTrees.class.equals(cls))</b>
<b class="nc"><i>73</i>&nbsp;			return new RTreesClassifier();</b>
<i>74</i>&nbsp;
<b class="nc"><i>75</i>&nbsp;		if (Boost.class.equals(cls))</b>
<b class="nc"><i>76</i>&nbsp;			return new BoostClassifier();</b>
<i>77</i>&nbsp;		
<b class="nc"><i>78</i>&nbsp;		if (DTrees.class.equals(cls))	</b>
<b class="nc"><i>79</i>&nbsp;			return new DTreesClassifier();</b>
<i>80</i>&nbsp;		
<b class="nc"><i>81</i>&nbsp;		if (KNearest.class.equals(cls))</b>
<b class="nc"><i>82</i>&nbsp;			return new KNearestClassifierCV();</b>
<i>83</i>&nbsp;		
<b class="nc"><i>84</i>&nbsp;		if (ANN_MLP.class.equals(cls))</b>
<b class="nc"><i>85</i>&nbsp;			return new ANNClassifierCV();</b>
<i>86</i>&nbsp;		
<b class="nc"><i>87</i>&nbsp;		if (LogisticRegression.class.equals(cls))</b>
<b class="nc"><i>88</i>&nbsp;			return new LogisticRegressionClassifier();</b>
<i>89</i>&nbsp;		
<b class="nc"><i>90</i>&nbsp;		if (EM.class.equals(cls))</b>
<b class="nc"><i>91</i>&nbsp;			return new EMClusterer();</b>
<i>92</i>&nbsp;
<b class="nc"><i>93</i>&nbsp;		if (NormalBayesClassifier.class.equals(cls))</b>
<b class="nc"><i>94</i>&nbsp;			return new NormalBayesClassifierCV();</b>
<i>95</i>&nbsp;		
<b class="nc"><i>96</i>&nbsp;		if (SVM.class.equals(cls))</b>
<b class="nc"><i>97</i>&nbsp;			return new SVMClassifierCV();</b>
<i>98</i>&nbsp;		
<b class="nc"><i>99</i>&nbsp;		if (SVMSGD.class.equals(cls))</b>
<b class="nc"><i>100</i>&nbsp;			return new SVMSGDClassifierCV();</b>
<i>101</i>&nbsp;		
<b class="nc"><i>102</i>&nbsp;		throw new IllegalArgumentException(&quot;Unknown StatModel class &quot; + cls);</b>
<i>103</i>&nbsp;	}
<i>104</i>&nbsp;	
<i>105</i>&nbsp;	
<i>106</i>&nbsp;//	/**
<i>107</i>&nbsp;//	 * Create a multiclass {@link StatModel}. Currently removed because it is hard to use.
<i>108</i>&nbsp;//	 * @param cls
<i>109</i>&nbsp;//	 * @return
<i>110</i>&nbsp;//	 */
<i>111</i>&nbsp;//	public static OpenCVStatModel createMulticlassStatModel(Class&lt;? extends StatModel&gt; cls) {		
<i>112</i>&nbsp;//		if (ANN_MLP.class.equals(cls))
<i>113</i>&nbsp;//			return new MulticlassANNClassifierCV();
<i>114</i>&nbsp;//		
<i>115</i>&nbsp;//		throw new IllegalArgumentException(&quot;Unknown StatModel class &quot; + cls);
<i>116</i>&nbsp;//	}
<i>117</i>&nbsp;
<i>118</i>&nbsp;	
<i>119</i>&nbsp;	/**
<i>120</i>&nbsp;	 * Create an {@link OpenCVStatModel} by wrapping an existing {@link StatModel}.
<i>121</i>&nbsp;	 * @param statModel
<i>122</i>&nbsp;	 * @return
<i>123</i>&nbsp;	 */
<i>124</i>&nbsp;	public static OpenCVStatModel wrapStatModel(StatModel statModel) {
<b class="nc"><i>125</i>&nbsp;		var cls = statModel.getClass();</b>
<i>126</i>&nbsp;		
<b class="nc"><i>127</i>&nbsp;		if (RTrees.class.equals(cls))</b>
<b class="nc"><i>128</i>&nbsp;			return new RTreesClassifier((RTrees)statModel);</b>
<i>129</i>&nbsp;
<b class="nc"><i>130</i>&nbsp;		if (Boost.class.equals(cls))</b>
<b class="nc"><i>131</i>&nbsp;			return new BoostClassifier((Boost)statModel);</b>
<i>132</i>&nbsp;		
<b class="nc"><i>133</i>&nbsp;		if (DTrees.class.equals(cls))	</b>
<b class="nc"><i>134</i>&nbsp;			return new DTreesClassifier((DTrees)statModel);</b>
<i>135</i>&nbsp;		
<b class="nc"><i>136</i>&nbsp;		if (KNearest.class.equals(cls))</b>
<b class="nc"><i>137</i>&nbsp;			return new KNearestClassifierCV((KNearest)statModel);</b>
<i>138</i>&nbsp;		
<b class="nc"><i>139</i>&nbsp;		if (ANN_MLP.class.equals(cls))</b>
<b class="nc"><i>140</i>&nbsp;			return new ANNClassifierCV((ANN_MLP)statModel);</b>
<i>141</i>&nbsp;		
<b class="nc"><i>142</i>&nbsp;		if (LogisticRegression.class.equals(cls))</b>
<b class="nc"><i>143</i>&nbsp;			return new LogisticRegressionClassifier((LogisticRegression)statModel);</b>
<i>144</i>&nbsp;		
<b class="nc"><i>145</i>&nbsp;		if (EM.class.equals(cls))</b>
<b class="nc"><i>146</i>&nbsp;			return new EMClusterer((EM)statModel);</b>
<i>147</i>&nbsp;
<b class="nc"><i>148</i>&nbsp;		if (NormalBayesClassifier.class.equals(cls))</b>
<b class="nc"><i>149</i>&nbsp;			return new NormalBayesClassifierCV((NormalBayesClassifier)statModel);</b>
<i>150</i>&nbsp;		
<b class="nc"><i>151</i>&nbsp;		if (SVM.class.equals(cls))</b>
<b class="nc"><i>152</i>&nbsp;			return new SVMClassifierCV((SVM)statModel);</b>
<i>153</i>&nbsp;		
<b class="nc"><i>154</i>&nbsp;		if (SVMSGD.class.equals(cls))</b>
<b class="nc"><i>155</i>&nbsp;			return new SVMSGDClassifierCV((SVMSGD)statModel);</b>
<i>156</i>&nbsp;		
<b class="nc"><i>157</i>&nbsp;		throw new IllegalArgumentException(&quot;Unknown StatModel class &quot; + cls);</b>
<i>158</i>&nbsp;	}
<i>159</i>&nbsp;	
<i>160</i>&nbsp;
<i>161</i>&nbsp;	/**
<i>162</i>&nbsp;	 * Wrapper class for a {@link StatModel}, which standardizes how training may be performed and 
<i>163</i>&nbsp;	 * parameters can be set.
<i>164</i>&nbsp;	 */
<i>165</i>&nbsp;	@JsonAdapter(OpenCVClassifierTypeAdapter.class)
<b class="nc"><i>166</i>&nbsp;	public static abstract class OpenCVStatModel {</b>
<i>167</i>&nbsp;		
<i>168</i>&nbsp;		/**
<i>169</i>&nbsp;		 * Classifier can handle missing (NaN) values
<i>170</i>&nbsp;		 * @return true if NaNs are supported, false otherwise
<i>171</i>&nbsp;		 */
<i>172</i>&nbsp;		public abstract boolean supportsMissingValues();
<i>173</i>&nbsp;		
<i>174</i>&nbsp;		/**
<i>175</i>&nbsp;		 * User-friendly, readable name for the classifier
<i>176</i>&nbsp;		 * @return the classifier name
<i>177</i>&nbsp;		 */
<i>178</i>&nbsp;		public abstract String getName();
<i>179</i>&nbsp;		
<i>180</i>&nbsp;		/**
<i>181</i>&nbsp;		 * Classifier has already been trained and is ready to predict.
<i>182</i>&nbsp;		 * @return true if the classifier is trained, false otherwise
<i>183</i>&nbsp;		 */
<i>184</i>&nbsp;		public abstract boolean isTrained();
<i>185</i>&nbsp;		
<i>186</i>&nbsp;		/**
<i>187</i>&nbsp;		 * Classifier is able to handle more than one outputs for a single sample.
<i>188</i>&nbsp;		 * @return true if multiclass classification is supported, false otherwise
<i>189</i>&nbsp;		 */
<i>190</i>&nbsp;		public abstract boolean supportsMulticlass();
<i>191</i>&nbsp;		
<i>192</i>&nbsp;		/**
<i>193</i>&nbsp;		 * Classifier can be trained interactively  (i.e. quickly).
<i>194</i>&nbsp;		 * @return true if interactive classification is supported, false otherwise
<i>195</i>&nbsp;		 */
<i>196</i>&nbsp;		public abstract boolean supportsAutoUpdate();
<i>197</i>&nbsp;		
<i>198</i>&nbsp;		/**
<i>199</i>&nbsp;		 * Classifier can output a prediction confidence (expressed between 0 and 1), 
<i>200</i>&nbsp;		 * so may be interpreted as a probability... even if it isn&#39;t necessarily one.
<i>201</i>&nbsp;		 * @return true if (pseudo-)probabilities can be provided
<i>202</i>&nbsp;		 */
<i>203</i>&nbsp;		public abstract boolean supportsProbabilities();
<i>204</i>&nbsp;		
<i>205</i>&nbsp;		/**
<i>206</i>&nbsp;		 * Retrieve a list of adjustable parameter that can be used to customize the classifier.
<i>207</i>&nbsp;		 * After making changes to the {@link ParameterList}, the classifier should be retrained 
<i>208</i>&nbsp;		 * before being used.
<i>209</i>&nbsp;		 * @return the parameter list for this classifier
<i>210</i>&nbsp;		 */
<i>211</i>&nbsp;		public abstract ParameterList getParameterList();
<i>212</i>&nbsp;				
<i>213</i>&nbsp;		/**
<i>214</i>&nbsp;		 * Create training data in the format required by this classifier.
<i>215</i>&nbsp;		 * @param samples
<i>216</i>&nbsp;		 * @param targets
<i>217</i>&nbsp;		 * @param weights optional weights
<i>218</i>&nbsp;		 * @param doMulticlass 
<i>219</i>&nbsp;		 * @return
<i>220</i>&nbsp;		 * @see #train(TrainData)
<i>221</i>&nbsp;		 */
<i>222</i>&nbsp;		public abstract TrainData createTrainData(Mat samples, Mat targets, Mat weights, boolean doMulticlass);
<i>223</i>&nbsp;		
<i>224</i>&nbsp;		/**
<i>225</i>&nbsp;		 * Train the classifier using data in an appropriate format.
<i>226</i>&nbsp;		 * @param trainData
<i>227</i>&nbsp;		 * @see #createTrainData(Mat, Mat, Mat, boolean)
<i>228</i>&nbsp;		 */
<i>229</i>&nbsp;		public abstract void train(TrainData trainData);
<i>230</i>&nbsp;
<i>231</i>&nbsp;		/**
<i>232</i>&nbsp;		 * Apply classification, optionally requesting probability estimates.
<i>233</i>&nbsp;		 * &lt;p&gt;
<i>234</i>&nbsp;		 * Not all StatModels are capable of estimating probability values, in which case 
<i>235</i>&nbsp;		 * probabilities will be null (if not supplied) or an empty matrix.
<i>236</i>&nbsp;		 * &lt;p&gt;
<i>237</i>&nbsp;		 * Note also that if probabilities are required, these will not necessarily be normalized 
<i>238</i>&nbsp;		 * between 0 and 1 (although they generally are).  They represent a best-effort for the 
<i>239</i>&nbsp;		 * StatModel to provide confidence values, but are not (necessarily) strictly probabilities.
<i>240</i>&nbsp;		 * &lt;p&gt;
<i>241</i>&nbsp;		 * For example, RTrees estimates probabilities based on the proportion of votes for the &#39;winning&#39; 
<i>242</i>&nbsp;		 * classification.
<i>243</i>&nbsp;		 * 
<i>244</i>&nbsp;		 * @param samples the input samples
<i>245</i>&nbsp;		 * @param results a Mat to receive the results
<i>246</i>&nbsp;		 * @param probabilities a Mat to receive probability estimates, or null if probabilities are not needed
<i>247</i>&nbsp;		 */
<i>248</i>&nbsp;		public abstract void predict(Mat samples, Mat results, Mat probabilities);
<i>249</i>&nbsp;		
<i>250</i>&nbsp;		abstract StatModel getStatModel();
<i>251</i>&nbsp;		
<i>252</i>&nbsp;		@Override
<i>253</i>&nbsp;		public String toString() {
<b class="nc"><i>254</i>&nbsp;			return String.format(&quot;OpenCV &quot;, getStatModel().getClass().getSimpleName());</b>
<i>255</i>&nbsp;		}
<i>256</i>&nbsp;		
<i>257</i>&nbsp;	}
<i>258</i>&nbsp;	
<i>259</i>&nbsp;	
<b class="nc"><i>260</i>&nbsp;	static class OpenCVClassifierTypeAdapter extends TypeAdapter&lt;OpenCVStatModel&gt; {</b>
<i>261</i>&nbsp;
<i>262</i>&nbsp;		@Override
<i>263</i>&nbsp;		public void write(JsonWriter out, OpenCVStatModel value) throws IOException {
<b class="nc"><i>264</i>&nbsp;			OpenCVTypeAdapters.getTypeAdaptor(StatModel.class).write(out, value.getStatModel());</b>
<i>265</i>&nbsp;		}
<i>266</i>&nbsp;
<i>267</i>&nbsp;		@Override
<i>268</i>&nbsp;		public OpenCVStatModel read(JsonReader in) throws IOException {
<b class="nc"><i>269</i>&nbsp;			var statModel = OpenCVTypeAdapters.getTypeAdaptor(StatModel.class).read(in);</b>
<b class="nc"><i>270</i>&nbsp;			return wrapStatModel(statModel);</b>
<i>271</i>&nbsp;//			return new DefaultOpenCVStatModel&lt;StatModel&gt;(statModel);
<i>272</i>&nbsp;		}
<i>273</i>&nbsp;		
<i>274</i>&nbsp;	}
<i>275</i>&nbsp;	
<i>276</i>&nbsp;	
<i>277</i>&nbsp;	
<i>278</i>&nbsp;	static abstract class AbstractOpenCVClassifierML&lt;T extends StatModel&gt; extends OpenCVStatModel {
<i>279</i>&nbsp;
<i>280</i>&nbsp;		@JsonAdapter(OpenCVTypeAdapters.OpenCVTypeAdaptorFactory.class)
<i>281</i>&nbsp;		private T model;
<i>282</i>&nbsp;		private transient ParameterList params; // Should take defaults from the serialized model
<i>283</i>&nbsp;		
<b class="nc"><i>284</i>&nbsp;		transient ReentrantReadWriteLock lock = new ReentrantReadWriteLock();</b>
<i>285</i>&nbsp;		
<i>286</i>&nbsp;		abstract ParameterList createParameterList(T model);
<i>287</i>&nbsp;		
<i>288</i>&nbsp;		abstract T createStatModel();
<i>289</i>&nbsp;		
<i>290</i>&nbsp;		abstract void updateModel(T model, ParameterList params, TrainData trainData);
<i>291</i>&nbsp;		
<i>292</i>&nbsp;		AbstractOpenCVClassifierML() {}
<i>293</i>&nbsp;		
<b class="nc"><i>294</i>&nbsp;		AbstractOpenCVClassifierML(T model) {</b>
<b class="nc"><i>295</i>&nbsp;			this.model = model;</b>
<b class="nc"><i>296</i>&nbsp;			params = createParameterList(model);</b>
<i>297</i>&nbsp;		}
<i>298</i>&nbsp;		
<i>299</i>&nbsp;		/**
<i>300</i>&nbsp;		 * Returns false (the default value).
<i>301</i>&nbsp;		 */
<i>302</i>&nbsp;		@Override
<i>303</i>&nbsp;		public boolean supportsMulticlass() {
<b class="nc"><i>304</i>&nbsp;			return false;</b>
<i>305</i>&nbsp;		}
<i>306</i>&nbsp;		
<i>307</i>&nbsp;		/**
<i>308</i>&nbsp;		 * Returns true (the default value).
<i>309</i>&nbsp;		 */
<i>310</i>&nbsp;		@Override
<i>311</i>&nbsp;		public boolean supportsAutoUpdate() {
<b class="nc"><i>312</i>&nbsp;			return true;</b>
<i>313</i>&nbsp;		}
<i>314</i>&nbsp;		
<i>315</i>&nbsp;		@Override
<i>316</i>&nbsp;		public boolean supportsProbabilities() {
<b class="nc"><i>317</i>&nbsp;			var model = getStatModel();</b>
<b class="nc"><i>318</i>&nbsp;			return model instanceof RTrees ||</b>
<i>319</i>&nbsp;					model instanceof ANN_MLP ||
<i>320</i>&nbsp;					model instanceof NormalBayesClassifier;
<i>321</i>&nbsp;		}
<i>322</i>&nbsp;		
<i>323</i>&nbsp;		@Override
<i>324</i>&nbsp;		T getStatModel() {
<b class="nc"><i>325</i>&nbsp;			if (model == null)</b>
<b class="nc"><i>326</i>&nbsp;				model = createStatModel();</b>
<b class="nc"><i>327</i>&nbsp;			return model;</b>
<i>328</i>&nbsp;		}
<i>329</i>&nbsp;		
<i>330</i>&nbsp;		@Override
<i>331</i>&nbsp;		public boolean isTrained() {
<b class="nc"><i>332</i>&nbsp;			return getStatModel().isTrained();</b>
<i>333</i>&nbsp;		}
<i>334</i>&nbsp;		
<i>335</i>&nbsp;		@Override
<i>336</i>&nbsp;		public ParameterList getParameterList() {
<b class="nc"><i>337</i>&nbsp;			if (params == null)</b>
<b class="nc"><i>338</i>&nbsp;				params = createParameterList(getStatModel());</b>
<b class="nc"><i>339</i>&nbsp;			return params;</b>
<i>340</i>&nbsp;		}
<i>341</i>&nbsp;				
<i>342</i>&nbsp;		@Override
<i>343</i>&nbsp;		public String toString() {
<b class="nc"><i>344</i>&nbsp;			return getName();</b>
<i>345</i>&nbsp;		}
<i>346</i>&nbsp;		
<i>347</i>&nbsp;		@Override
<i>348</i>&nbsp;		public TrainData createTrainData(Mat samples, Mat targets, Mat weights, boolean doMulticlass) {
<b class="nc"><i>349</i>&nbsp;			if (doMulticlass &amp;&amp; !supportsMulticlass())</b>
<b class="nc"><i>350</i>&nbsp;				logger.warn(&quot;Multiclass classification requested, but not supported&quot;);</b>
<b class="nc"><i>351</i>&nbsp;			if (useUMat()) {</b>
<b class="nc"><i>352</i>&nbsp;				UMat uSamples = samples.getUMat(opencv_core.ACCESS_READ);</b>
<b class="nc"><i>353</i>&nbsp;				UMat uTargets = targets.getUMat(opencv_core.ACCESS_READ);</b>
<b class="nc"><i>354</i>&nbsp;				if (weights == null || weights.empty())</b>
<b class="nc"><i>355</i>&nbsp;					return TrainData.create(uSamples, opencv_ml.ROW_SAMPLE, uTargets);</b>
<b class="nc"><i>356</i>&nbsp;				UMat uWeights = weights.getUMat(opencv_core.ACCESS_READ);</b>
<b class="nc"><i>357</i>&nbsp;				return TrainData.create(uSamples, opencv_ml.ROW_SAMPLE, uTargets, null, null, uWeights, null);				</b>
<i>358</i>&nbsp;			}
<b class="nc"><i>359</i>&nbsp;			if (weights == null || weights.empty())</b>
<b class="nc"><i>360</i>&nbsp;				return TrainData.create(samples, opencv_ml.ROW_SAMPLE, targets);</b>
<i>361</i>&nbsp;			else
<b class="nc"><i>362</i>&nbsp;				return TrainData.create(samples, opencv_ml.ROW_SAMPLE, targets, null, null, weights, null);</b>
<i>363</i>&nbsp;		}
<i>364</i>&nbsp;		
<i>365</i>&nbsp;		boolean useUMat() {
<b class="nc"><i>366</i>&nbsp;			return false;</b>
<i>367</i>&nbsp;		}
<i>368</i>&nbsp;
<i>369</i>&nbsp;		@Override
<i>370</i>&nbsp;		public void train(TrainData trainData) {
<b class="nc"><i>371</i>&nbsp;			lock.writeLock().lock();</b>
<i>372</i>&nbsp;			try {
<b class="nc"><i>373</i>&nbsp;				trainWithLock(trainData);</b>
<i>374</i>&nbsp;			} finally {
<b class="nc"><i>375</i>&nbsp;				lock.writeLock().unlock();</b>
<b class="nc"><i>376</i>&nbsp;			}</b>
<i>377</i>&nbsp;		}
<i>378</i>&nbsp;		
<i>379</i>&nbsp;		/**
<i>380</i>&nbsp;		 * Implement trainWithLock rather than train directly to ensure a lock is set 
<i>381</i>&nbsp;		 * when training, which can be used to prevent prediction occurring simultaneously.
<i>382</i>&nbsp;		 * 
<i>383</i>&nbsp;		 * @param trainData
<i>384</i>&nbsp;		 * 
<i>385</i>&nbsp;		 * @see #predictWithLock
<i>386</i>&nbsp;		 */
<i>387</i>&nbsp;		public void trainWithLock(TrainData trainData) {
<b class="nc"><i>388</i>&nbsp;			var statModel = getStatModel();</b>
<b class="nc"><i>389</i>&nbsp;			opencv_core.setRNGSeed(1012);</b>
<b class="nc"><i>390</i>&nbsp;			updateModel(statModel, getParameterList(), trainData);</b>
<i>391</i>&nbsp;//			statModel.train(trainData);
<b class="nc"><i>392</i>&nbsp;			statModel.train(trainData, getTrainFlags());</b>
<i>393</i>&nbsp;		}
<i>394</i>&nbsp;		
<i>395</i>&nbsp;		protected int getTrainFlags() {
<b class="nc"><i>396</i>&nbsp;			return 0;</b>
<i>397</i>&nbsp;		}
<i>398</i>&nbsp;		
<i>399</i>&nbsp;		abstract Class&lt;? extends StatModel&gt; getStatModelClass();
<i>400</i>&nbsp;
<i>401</i>&nbsp;		@Override
<i>402</i>&nbsp;		public String getName() {
<b class="nc"><i>403</i>&nbsp;			var cls = getStatModelClass();</b>
<i>404</i>&nbsp;			
<b class="nc"><i>405</i>&nbsp;			if (ANN_MLP.class.equals(cls))</b>
<b class="nc"><i>406</i>&nbsp;				return &quot;Artificial neural network (ANN_MLP)&quot;;</b>
<b class="nc"><i>407</i>&nbsp;			else if (RTrees.class.equals(cls))</b>
<b class="nc"><i>408</i>&nbsp;				return &quot;Random trees (RTrees)&quot;;</b>
<b class="nc"><i>409</i>&nbsp;			else if (Boost.class.equals(cls))</b>
<b class="nc"><i>410</i>&nbsp;				return &quot;Boosted trees (Boost)&quot;;</b>
<b class="nc"><i>411</i>&nbsp;			else if (DTrees.class.equals(cls))</b>
<b class="nc"><i>412</i>&nbsp;				return &quot;Decision tree (DTrees)&quot;;</b>
<b class="nc"><i>413</i>&nbsp;			else if (EM.class.equals(cls))</b>
<b class="nc"><i>414</i>&nbsp;				return &quot;Expectation maximization&quot;;</b>
<b class="nc"><i>415</i>&nbsp;			else if (KNearest.class.equals(cls))</b>
<b class="nc"><i>416</i>&nbsp;				return &quot;K nearest neighbor&quot;;</b>
<b class="nc"><i>417</i>&nbsp;			else if (LogisticRegression.class.equals(cls))</b>
<b class="nc"><i>418</i>&nbsp;				return &quot;Logistic regression&quot;;</b>
<b class="nc"><i>419</i>&nbsp;			else if (NormalBayesClassifier.class.equals(cls))</b>
<b class="nc"><i>420</i>&nbsp;				return &quot;Normal Bayes classifier&quot;;</b>
<i>421</i>&nbsp;			
<b class="nc"><i>422</i>&nbsp;			return getStatModel().getClass().getSimpleName();</b>
<i>423</i>&nbsp;		}
<i>424</i>&nbsp;		
<i>425</i>&nbsp;		/**
<i>426</i>&nbsp;		 * Default implementation calling
<i>427</i>&nbsp;		 * &lt;pre&gt;
<i>428</i>&nbsp;		 * statModel.predict(samples, results, 0);
<i>429</i>&nbsp;		 * &lt;/pre&gt;
<i>430</i>&nbsp;		 * before attempting to sanitize the outcome so that results always contains a signed int Mat containing 
<i>431</i>&nbsp;		 * classifications.
<i>432</i>&nbsp;		 * &lt;p&gt;
<i>433</i>&nbsp;		 * If results originally had more than 1 column, it will be returned as probabilities 
<i>434</i>&nbsp;		 * (if probabilities is not null);
<i>435</i>&nbsp;		 * {@code probabilities} will be an empty matrix (i.e. no probabilities calculated).
<i>436</i>&nbsp;		 */
<i>437</i>&nbsp;		@Override
<i>438</i>&nbsp;		public void predict(Mat samples, Mat results, Mat probabilities) {
<b class="nc"><i>439</i>&nbsp;			lock.readLock().lock();</b>
<i>440</i>&nbsp;			try {
<b class="nc"><i>441</i>&nbsp;				predictWithLock(samples, results, probabilities);</b>
<i>442</i>&nbsp;			} finally {
<b class="nc"><i>443</i>&nbsp;				lock.readLock().unlock();</b>
<b class="nc"><i>444</i>&nbsp;			}</b>
<i>445</i>&nbsp;		}
<i>446</i>&nbsp;		
<i>447</i>&nbsp;		/**
<i>448</i>&nbsp;		 * Implement predictWithLock rather than predict to ensure predict is not called while 
<i>449</i>&nbsp;		 * training.
<i>450</i>&nbsp;		 * 
<i>451</i>&nbsp;		 * @param samples
<i>452</i>&nbsp;		 * @param results
<i>453</i>&nbsp;		 * @param probabilities
<i>454</i>&nbsp;		 * 
<i>455</i>&nbsp;		 * @see #trainWithLock
<i>456</i>&nbsp;		 */
<i>457</i>&nbsp;		protected void predictWithLock(Mat samples, Mat results, Mat probabilities) {
<b class="nc"><i>458</i>&nbsp;			var statModel = getStatModel();</b>
<b class="nc"><i>459</i>&nbsp;			statModel.predict(samples, results, 0);</b>
<i>460</i>&nbsp;			
<b class="nc"><i>461</i>&nbsp;			int nSamples = results.rows();</b>
<i>462</i>&nbsp;			
<b class="nc"><i>463</i>&nbsp;			if (results.cols() &gt; 1) {</b>
<b class="nc"><i>464</i>&nbsp;				var indexer = results.createIndexer();</b>
<b class="nc"><i>465</i>&nbsp;				int nClasses = results.cols();</b>
<i>466</i>&nbsp;				
<b class="nc"><i>467</i>&nbsp;				var matResultsnew = new Mat(nSamples, 1, opencv_core.CV_32SC1);</b>
<b class="nc"><i>468</i>&nbsp;				IntIndexer idxResults = matResultsnew.createIndexer();</b>
<b class="nc"><i>469</i>&nbsp;				if (probabilities != null) {</b>
<b class="nc"><i>470</i>&nbsp;					probabilities.create(nSamples, nClasses, opencv_core.CV_32FC1);</b>
<b class="nc"><i>471</i>&nbsp;					probabilities.put(results);</b>
<i>472</i>&nbsp;				}
<i>473</i>&nbsp;				
<b class="nc"><i>474</i>&nbsp;				var inds = new long[2];</b>
<b class="nc"><i>475</i>&nbsp;				for (int row = 0; row &lt; nSamples; row++) {</b>
<b class="nc"><i>476</i>&nbsp;					double maxValue = Double.NEGATIVE_INFINITY;</b>
<b class="nc"><i>477</i>&nbsp;					int maxInd = -1;</b>
<b class="nc"><i>478</i>&nbsp;					inds[0] = row;</b>
<b class="nc"><i>479</i>&nbsp;					for (long c = 0; c &lt; nClasses; c++) {</b>
<b class="nc"><i>480</i>&nbsp;						inds[1] = c;</b>
<b class="nc"><i>481</i>&nbsp;						double val = indexer.getDouble(inds);</b>
<b class="nc"><i>482</i>&nbsp;						if (val &gt; maxValue) {</b>
<b class="nc"><i>483</i>&nbsp;							maxValue = val;</b>
<b class="nc"><i>484</i>&nbsp;							maxInd = (int)c;</b>
<i>485</i>&nbsp;						}
<i>486</i>&nbsp;					}
<b class="nc"><i>487</i>&nbsp;					idxResults.put(row,  maxInd);</b>
<i>488</i>&nbsp;				}
<b class="nc"><i>489</i>&nbsp;				indexer.release();</b>
<b class="nc"><i>490</i>&nbsp;				idxResults.release();</b>
<b class="nc"><i>491</i>&nbsp;				results.put(matResultsnew);</b>
<b class="nc"><i>492</i>&nbsp;			} else {</b>
<b class="nc"><i>493</i>&nbsp;				results.convertTo(results, opencv_core.CV_32SC1);</b>
<b class="nc"><i>494</i>&nbsp;				if (probabilities != null) {</b>
<i>495</i>&nbsp;					// Ensure we have an empty matrix for probabilities
<b class="nc"><i>496</i>&nbsp;					probabilities.create(0, 0, opencv_core.CV_32FC1);</b>
<i>497</i>&nbsp;				}
<i>498</i>&nbsp;			}
<i>499</i>&nbsp;		}
<i>500</i>&nbsp;		
<i>501</i>&nbsp;		/**
<i>502</i>&nbsp;		 * Tree classifiers in OpenCV support missing values, others do not.
<i>503</i>&nbsp;		 */
<i>504</i>&nbsp;		@Override
<i>505</i>&nbsp;		public boolean supportsMissingValues() {
<b class="nc"><i>506</i>&nbsp;			return getStatModel() instanceof DTrees;</b>
<i>507</i>&nbsp;		}
<i>508</i>&nbsp;		
<i>509</i>&nbsp;		
<i>510</i>&nbsp;	}
<i>511</i>&nbsp;	
<i>512</i>&nbsp;	
<i>513</i>&nbsp;	/**
<i>514</i>&nbsp;	 * Add TermCriteria parameters to an existing list.
<i>515</i>&nbsp;	 * This will be an int parameter &#39;termIterators&#39; and a double parameter &#39;termEpsilon&#39;.
<i>516</i>&nbsp;	 * 
<i>517</i>&nbsp;	 * @param params the parameter list to which the parameters should be added
<i>518</i>&nbsp;	 * @param defaultCriteria the current (default) TermCriteria, used to initialize the values
<i>519</i>&nbsp;	 * 
<i>520</i>&nbsp;	 * @see #updateTermCriteria(ParameterList, TermCriteria)
<i>521</i>&nbsp;	 */
<i>522</i>&nbsp;	static void addTerminationCriteriaParameters(ParameterList params, TermCriteria defaultCriteria) {
<i>523</i>&nbsp;		// Set termination criteria
<b class="nc"><i>524</i>&nbsp;		params.addTitleParameter(&quot;Termination criteria&quot;);</b>
<b class="nc"><i>525</i>&nbsp;		params.addIntParameter(&quot;termIterations&quot;, &quot;Max iterations&quot;, defaultCriteria.maxCount(), null, &quot;Maximum number of iterations for training&quot;);</b>
<b class="nc"><i>526</i>&nbsp;		params.addDoubleParameter(&quot;termEpsilon&quot;, &quot;Epsilon&quot;, defaultCriteria.epsilon(), null, &quot;Desired accuracy for training&quot;);</b>
<i>527</i>&nbsp;	}
<i>528</i>&nbsp;	
<i>529</i>&nbsp;	/**
<i>530</i>&nbsp;	 * Parse the TermCriteria parameters, returning a new object if needed.
<i>531</i>&nbsp;	 * 
<i>532</i>&nbsp;	 * @param params
<i>533</i>&nbsp;	 * @param termCriteria
<i>534</i>&nbsp;	 * @return termCriteria if the parameters are unchanged, or a new TermCriteria reflecting the parameters if required
<i>535</i>&nbsp;	 * 
<i>536</i>&nbsp;	 * @see #addTerminationCriteriaParameters(ParameterList, TermCriteria)
<i>537</i>&nbsp;	 */
<i>538</i>&nbsp;	static TermCriteria updateTermCriteria(ParameterList params, TermCriteria termCriteria) {
<b class="nc"><i>539</i>&nbsp;		int count = params.getIntParameterValue(&quot;termIterations&quot;);</b>
<b class="nc"><i>540</i>&nbsp;		double epsilon = params.getDoubleParameterValue(&quot;termEpsilon&quot;);</b>
<i>541</i>&nbsp;		
<b class="nc"><i>542</i>&nbsp;		if (termCriteria != null &amp;&amp; termCriteria.maxCount() == count &amp;&amp; termCriteria.epsilon() == epsilon)</b>
<b class="nc"><i>543</i>&nbsp;			return termCriteria;</b>
<i>544</i>&nbsp;		
<b class="nc"><i>545</i>&nbsp;		int type = 0;</b>
<b class="nc"><i>546</i>&nbsp;		int termIterations = params.getIntParameterValue(&quot;termIterations&quot;);</b>
<b class="nc"><i>547</i>&nbsp;		double termEpsilon = params.getDoubleParameterValue(&quot;termEpsilon&quot;);</b>
<b class="nc"><i>548</i>&nbsp;		if (termIterations &gt;= 1)</b>
<b class="nc"><i>549</i>&nbsp;			type += TermCriteria.MAX_ITER;</b>
<b class="nc"><i>550</i>&nbsp;		if (termIterations &gt; 0)</b>
<b class="nc"><i>551</i>&nbsp;			type += TermCriteria.EPS;</b>
<b class="nc"><i>552</i>&nbsp;		return new TermCriteria(type, termIterations, termEpsilon);</b>
<i>553</i>&nbsp;	}
<i>554</i>&nbsp;	
<i>555</i>&nbsp;	
<i>556</i>&nbsp;	static class DefaultOpenCVStatModel&lt;T extends StatModel&gt; extends AbstractOpenCVClassifierML&lt;T&gt; {
<i>557</i>&nbsp;
<i>558</i>&nbsp;		DefaultOpenCVStatModel(T model) {
<b class="nc"><i>559</i>&nbsp;			super(model);</b>
<i>560</i>&nbsp;		}
<i>561</i>&nbsp;		
<i>562</i>&nbsp;		@Override
<i>563</i>&nbsp;		ParameterList createParameterList(T model) {
<b class="nc"><i>564</i>&nbsp;			return new ParameterList();</b>
<i>565</i>&nbsp;		}
<i>566</i>&nbsp;		
<i>567</i>&nbsp;		@Override
<i>568</i>&nbsp;		T createStatModel() {
<b class="nc"><i>569</i>&nbsp;			return getStatModel();</b>
<i>570</i>&nbsp;		}
<i>571</i>&nbsp;
<i>572</i>&nbsp;		/**
<i>573</i>&nbsp;		 * No updates performed.
<i>574</i>&nbsp;		 */
<i>575</i>&nbsp;		@Override
<i>576</i>&nbsp;		void updateModel(T model, ParameterList params, TrainData trainData) {
<i>577</i>&nbsp;			// TODO Auto-generated method stub
<i>578</i>&nbsp;		}
<i>579</i>&nbsp;
<i>580</i>&nbsp;		@Override
<i>581</i>&nbsp;		Class&lt;? extends StatModel&gt; getStatModelClass() {
<b class="nc"><i>582</i>&nbsp;			return getStatModel().getClass();</b>
<i>583</i>&nbsp;		}
<i>584</i>&nbsp;		
<i>585</i>&nbsp;	}
<i>586</i>&nbsp;	
<i>587</i>&nbsp;	static abstract class AbstractTreeClassifier&lt;T extends DTrees&gt; extends AbstractOpenCVClassifierML&lt;T&gt; {
<i>588</i>&nbsp;
<i>589</i>&nbsp;		AbstractTreeClassifier() {
<b class="nc"><i>590</i>&nbsp;			super();</b>
<i>591</i>&nbsp;		}
<i>592</i>&nbsp;		
<i>593</i>&nbsp;		AbstractTreeClassifier(final T model) {
<b class="nc"><i>594</i>&nbsp;			super(model);</b>
<i>595</i>&nbsp;		}
<i>596</i>&nbsp;		
<i>597</i>&nbsp;		
<i>598</i>&nbsp;		@Override
<i>599</i>&nbsp;		ParameterList createParameterList(T model) {
<i>600</i>&nbsp;			
<b class="nc"><i>601</i>&nbsp;			int maxDepth = Math.min(model.getMaxDepth(), 1000);</b>
<b class="nc"><i>602</i>&nbsp;			int minSampleCount = model.getMinSampleCount();</b>
<i>603</i>&nbsp;//			float regressionAccuracy = model.getRegressionAccuracy();
<b class="nc"><i>604</i>&nbsp;			boolean use1SERule = model.getUse1SERule();</b>
<i>605</i>&nbsp;			
<i>606</i>&nbsp;			// Unused parameters
<i>607</i>&nbsp;//			int cvFolds = model.getCVFolds(); // Not implemented
<i>608</i>&nbsp;//			int maxCategories = model.getMaxCategories();
<i>609</i>&nbsp;//			boolean truncatePrunedTree = model.getTruncatePrunedTree();
<i>610</i>&nbsp;//			boolean useSurrogates = model.getUseSurrogates(); // Not implemented in OpenCV at this time
<i>611</i>&nbsp;
<i>612</i>&nbsp;			// TODO: Consider use of priors
<i>613</i>&nbsp;//			model.getPriors(null);
<i>614</i>&nbsp;
<b class="nc"><i>615</i>&nbsp;			ParameterList params = new ParameterList()</b>
<i>616</i>&nbsp;//					.addIntParameter(&quot;cvFolds&quot;, &quot;Cross-validation folds&quot;, cvFolds, &quot;Number of cross-validation folds to use when building the tree&quot;)
<b class="nc"><i>617</i>&nbsp;					.addIntParameter(&quot;maxDepth&quot;, &quot;Maximum tree depth&quot;, maxDepth, null, &quot;Maximum possible tree depth&quot;)</b>
<b class="nc"><i>618</i>&nbsp;					.addIntParameter(&quot;minSampleCount&quot;, &quot;Minimum sample count&quot;, minSampleCount, null, &quot;Minimum number of samples per node&quot;)</b>
<i>619</i>&nbsp;//					.addDoubleParameter(&quot;regressionAccuracy&quot;, &quot;Regression accuracy&quot;, regressionAccuracy, null, &quot;Termination criterion&quot;)
<b class="nc"><i>620</i>&nbsp;					.addBooleanParameter(&quot;use1SERule&quot;, &quot;Use 1SE rule&quot;, use1SERule, &quot;Harsher pruning, more compact tree&quot;)</b>
<i>621</i>&nbsp;					;
<i>622</i>&nbsp;			
<b class="nc"><i>623</i>&nbsp;			return params;</b>
<i>624</i>&nbsp;		}
<i>625</i>&nbsp;		
<i>626</i>&nbsp;		@Override
<i>627</i>&nbsp;		void updateModel(T model, ParameterList params, TrainData trainData) {
<i>628</i>&nbsp;			
<i>629</i>&nbsp;//			int cvFolds = params.getIntParameterValue(&quot;cvFolds&quot;);
<b class="nc"><i>630</i>&nbsp;			int maxDepth = params.getIntParameterValue(&quot;maxDepth&quot;);</b>
<b class="nc"><i>631</i>&nbsp;			int minSampleCount = params.getIntParameterValue(&quot;minSampleCount&quot;);</b>
<i>632</i>&nbsp;//			float regressionAccuracy = params.getDoubleParameterValue(&quot;regressionAccuracy&quot;).floatValue();
<b class="nc"><i>633</i>&nbsp;			boolean use1SERule = params.getBooleanParameterValue(&quot;use1SERule&quot;);</b>
<i>634</i>&nbsp;			
<i>635</i>&nbsp;//			model.setCVFolds(cvFolds &lt; 1 ? 1 : cvFolds);
<b class="nc"><i>636</i>&nbsp;			model.setCVFolds(0);</b>
<b class="nc"><i>637</i>&nbsp;			model.setMaxDepth(maxDepth &lt;= 0 ? Integer.MAX_VALUE : maxDepth);</b>
<b class="nc"><i>638</i>&nbsp;			model.setMinSampleCount(minSampleCount &lt; 1 ? 1 : minSampleCount);</b>
<i>639</i>&nbsp;//			model.setRegressionAccuracy(regressionAccuracy &lt; 1e-6f ? 1e-6f : regressionAccuracy);
<b class="nc"><i>640</i>&nbsp;			model.setUse1SERule(use1SERule);</b>
<i>641</i>&nbsp;		}
<i>642</i>&nbsp;		
<i>643</i>&nbsp;		
<i>644</i>&nbsp;	}
<i>645</i>&nbsp;	
<i>646</i>&nbsp;	/**
<i>647</i>&nbsp;	 * Classifier based on {@link DTrees}.
<i>648</i>&nbsp;	 */
<i>649</i>&nbsp;	public static class DTreesClassifier extends AbstractTreeClassifier&lt;DTrees&gt; {
<i>650</i>&nbsp;
<i>651</i>&nbsp;		DTreesClassifier() {
<b class="nc"><i>652</i>&nbsp;			super();</b>
<i>653</i>&nbsp;		}
<i>654</i>&nbsp;		
<i>655</i>&nbsp;		DTreesClassifier(final DTrees model) {
<b class="nc"><i>656</i>&nbsp;			super(model);</b>
<i>657</i>&nbsp;		}
<i>658</i>&nbsp;		
<i>659</i>&nbsp;		@Override
<i>660</i>&nbsp;		DTrees createStatModel() {
<b class="nc"><i>661</i>&nbsp;			return DTrees.create();</b>
<i>662</i>&nbsp;		}
<i>663</i>&nbsp;
<i>664</i>&nbsp;		@Override
<i>665</i>&nbsp;		Class&lt;? extends StatModel&gt; getStatModelClass() {
<b class="nc"><i>666</i>&nbsp;			return DTrees.class;</b>
<i>667</i>&nbsp;		}
<i>668</i>&nbsp;		
<i>669</i>&nbsp;	}
<i>670</i>&nbsp;	
<i>671</i>&nbsp;	/**
<i>672</i>&nbsp;	 * Classifier based on {@link RTrees}.
<i>673</i>&nbsp;	 */
<i>674</i>&nbsp;	public static class RTreesClassifier extends AbstractTreeClassifier&lt;RTrees&gt; {
<i>675</i>&nbsp;		
<i>676</i>&nbsp;		private double[] featureImportance;
<i>677</i>&nbsp;		
<i>678</i>&nbsp;		RTreesClassifier() {
<b class="nc"><i>679</i>&nbsp;			super();</b>
<i>680</i>&nbsp;		}
<i>681</i>&nbsp;		
<i>682</i>&nbsp;		RTreesClassifier(final RTrees model) {
<b class="nc"><i>683</i>&nbsp;			super(model);</b>
<i>684</i>&nbsp;		}
<i>685</i>&nbsp;		
<i>686</i>&nbsp;		@Override
<i>687</i>&nbsp;		RTrees createStatModel() {
<b class="nc"><i>688</i>&nbsp;			var model = RTrees.create();</b>
<b class="nc"><i>689</i>&nbsp;			model.setMaxDepth(0);</b>
<b class="nc"><i>690</i>&nbsp;			model.setTermCriteria(</b>
<i>691</i>&nbsp;					new TermCriteria(TermCriteria.COUNT, 50, 0));
<b class="nc"><i>692</i>&nbsp;			return model;</b>
<i>693</i>&nbsp;		}
<i>694</i>&nbsp;
<i>695</i>&nbsp;		@Override
<i>696</i>&nbsp;		ParameterList createParameterList(RTrees model) {
<b class="nc"><i>697</i>&nbsp;			ParameterList params = super.createParameterList(model);</b>
<i>698</i>&nbsp;			
<b class="nc"><i>699</i>&nbsp;			int activeVarCount = model.getActiveVarCount();</b>
<b class="nc"><i>700</i>&nbsp;			var termCrit = model.getTermCriteria();</b>
<b class="nc"><i>701</i>&nbsp;			int maxTrees = termCrit.maxCount();</b>
<b class="nc"><i>702</i>&nbsp;			double epsilon = termCrit.epsilon();</b>
<b class="nc"><i>703</i>&nbsp;			boolean calcImportance = model.getCalculateVarImportance();</b>
<i>704</i>&nbsp;			
<b class="nc"><i>705</i>&nbsp;			params.addIntParameter(&quot;activeVarCount&quot;, &quot;Active variable count&quot;, activeVarCount, null, &quot;Number of features per tree node (if &lt;=0, will use square root of number of features)&quot;);</b>
<b class="nc"><i>706</i>&nbsp;			params.addIntParameter(&quot;maxTrees&quot;, &quot;Maximum number of trees&quot;, maxTrees, null, &quot;Maximum possible number of trees - but viewer may be used if &#39;Termination epsilon&#39; is high&quot;);</b>
<b class="nc"><i>707</i>&nbsp;			params.addDoubleParameter(&quot;epsilon&quot;, &quot;Termination epsilon&quot;, epsilon, null, &quot;Termination criterion - if this is high, viewer trees may be used for classification&quot;);</b>
<b class="nc"><i>708</i>&nbsp;			params.addBooleanParameter(&quot;calcImportance&quot;, &quot;Calculate variable importance&quot;, calcImportance, &quot;Calculate estimate of each variable&#39;s importance (this impacts the results of the classifier!)&quot;);</b>
<b class="nc"><i>709</i>&nbsp;			return params;</b>
<i>710</i>&nbsp;		}
<i>711</i>&nbsp;		
<i>712</i>&nbsp;		@Override
<i>713</i>&nbsp;		public void train(TrainData trainData) {
<b class="nc"><i>714</i>&nbsp;			super.train(trainData);</b>
<b class="nc"><i>715</i>&nbsp;			var trees = getStatModel();</b>
<b class="nc"><i>716</i>&nbsp;			if (trees.getCalculateVarImportance()) {</b>
<i>717</i>&nbsp;//				synchronized (this) {
<b class="nc"><i>718</i>&nbsp;					var importance = trees.getVarImportance();</b>
<b class="nc"><i>719</i>&nbsp;					var indexer = importance.createIndexer();</b>
<b class="nc"><i>720</i>&nbsp;					int nFeatures = (int)indexer.size(0);</b>
<b class="nc"><i>721</i>&nbsp;					featureImportance = new double[nFeatures];</b>
<b class="nc"><i>722</i>&nbsp;					for (int r = 0; r &lt; nFeatures; r++) {</b>
<b class="nc"><i>723</i>&nbsp;						featureImportance[r] = indexer.getDouble(r);</b>
<i>724</i>&nbsp;					}
<b class="nc"><i>725</i>&nbsp;					indexer.release();</b>
<i>726</i>&nbsp;//				}
<b class="nc"><i>727</i>&nbsp;			} else</b>
<b class="nc"><i>728</i>&nbsp;				featureImportance = null;</b>
<i>729</i>&nbsp;		}
<i>730</i>&nbsp;		
<i>731</i>&nbsp;		/**
<i>732</i>&nbsp;		 * Check if the last time train was called, variable (feature) importance was calculated.
<i>733</i>&nbsp;		 * @return
<i>734</i>&nbsp;		 * 
<i>735</i>&nbsp;		 * @see #getFeatureImportance()
<i>736</i>&nbsp;		 */
<i>737</i>&nbsp;		public synchronized boolean hasFeatureImportance() {
<b class="nc"><i>738</i>&nbsp;			return featureImportance != null;</b>
<i>739</i>&nbsp;		}
<i>740</i>&nbsp;		
<i>741</i>&nbsp;		/**
<i>742</i>&nbsp;		 * Request the variable importance values from the last trained RTrees classifier, if available.
<i>743</i>&nbsp;		 * 
<i>744</i>&nbsp;		 * @return the ordered array of importance values, or null if this is unavailable
<i>745</i>&nbsp;		 * 
<i>746</i>&nbsp;		 * @see #hasFeatureImportance()
<i>747</i>&nbsp;		 */
<i>748</i>&nbsp;		public double[] getFeatureImportance() {
<b class="nc"><i>749</i>&nbsp;			return featureImportance == null ? null : featureImportance.clone();</b>
<i>750</i>&nbsp;		}
<i>751</i>&nbsp;
<i>752</i>&nbsp;		@Override
<i>753</i>&nbsp;		void updateModel(RTrees model, ParameterList params, TrainData trainData) {
<i>754</i>&nbsp;			
<b class="nc"><i>755</i>&nbsp;			super.updateModel(model, params, trainData);</b>
<i>756</i>&nbsp;
<b class="nc"><i>757</i>&nbsp;			int activeVarCount = params.getIntParameterValue(&quot;activeVarCount&quot;);</b>
<b class="nc"><i>758</i>&nbsp;			int maxTrees = params.getIntParameterValue(&quot;maxTrees&quot;);</b>
<b class="nc"><i>759</i>&nbsp;			double epsilon = params.getDoubleParameterValue(&quot;epsilon&quot;);</b>
<b class="nc"><i>760</i>&nbsp;			boolean calcImportance = params.getBooleanParameterValue(&quot;calcImportance&quot;);</b>
<i>761</i>&nbsp;
<b class="nc"><i>762</i>&nbsp;			int type = 0;</b>
<b class="nc"><i>763</i>&nbsp;			if (maxTrees &gt;= 1)</b>
<b class="nc"><i>764</i>&nbsp;				type += TermCriteria.MAX_ITER;</b>
<b class="nc"><i>765</i>&nbsp;			if (epsilon &gt; 0)</b>
<b class="nc"><i>766</i>&nbsp;				type += TermCriteria.EPS;</b>
<b class="nc"><i>767</i>&nbsp;			var termCrit = new TermCriteria(type, maxTrees, epsilon);</b>
<i>768</i>&nbsp;
<b class="nc"><i>769</i>&nbsp;			model.setActiveVarCount(activeVarCount);</b>
<b class="nc"><i>770</i>&nbsp;			model.setUseSurrogates(false); // Not implemented, throws an exception</b>
<b class="nc"><i>771</i>&nbsp;			model.setTermCriteria(termCrit);</b>
<b class="nc"><i>772</i>&nbsp;			model.setCalculateVarImportance(calcImportance);</b>
<i>773</i>&nbsp;		}
<i>774</i>&nbsp;		
<i>775</i>&nbsp;		@Override
<i>776</i>&nbsp;		Class&lt;? extends StatModel&gt; getStatModelClass() {
<b class="nc"><i>777</i>&nbsp;			return RTrees.class;</b>
<i>778</i>&nbsp;		}
<i>779</i>&nbsp;
<i>780</i>&nbsp;		
<i>781</i>&nbsp;		@Override
<i>782</i>&nbsp;		public void predictWithLock(Mat samples, Mat results, Mat probabilities) {
<i>783</i>&nbsp;			// If we don&#39;t need probabilities, it&#39;s quite straightforward
<b class="nc"><i>784</i>&nbsp;			var model = getStatModel();</b>
<b class="nc"><i>785</i>&nbsp;			if (probabilities == null) {</b>
<b class="nc"><i>786</i>&nbsp;				model.predict(samples, results,  RTrees.PREDICT_AUTO);</b>
<i>787</i>&nbsp;//				var idx = samples.createIndexer();
<i>788</i>&nbsp;//				idx.release();
<b class="nc"><i>789</i>&nbsp;				results.convertTo(results, opencv_core.CV_32SC1);</b>
<i>790</i>&nbsp;				return;
<i>791</i>&nbsp;			}
<i>792</i>&nbsp;			
<i>793</i>&nbsp;			// If we want probabilities, we can try our best using the votes
<b class="nc"><i>794</i>&nbsp;			var votes = new Mat();</b>
<b class="nc"><i>795</i>&nbsp;			model.getVotes(samples, votes, RTrees.PREDICT_AUTO);</b>
<i>796</i>&nbsp;			
<b class="nc"><i>797</i>&nbsp;			int nClasses = votes.cols();</b>
<b class="nc"><i>798</i>&nbsp;			int nSamples = samples.rows();</b>
<b class="nc"><i>799</i>&nbsp;			IntIndexer indexer = votes.createIndexer();</b>
<i>800</i>&nbsp;			
<i>801</i>&nbsp;			// Preallocate output
<b class="nc"><i>802</i>&nbsp;			probabilities.create(nSamples, nClasses, opencv_core.CV_32FC1);</b>
<b class="nc"><i>803</i>&nbsp;			FloatIndexer idxProbabilities = probabilities.createIndexer();</b>
<b class="nc"><i>804</i>&nbsp;			results.create(nSamples, 1, opencv_core.CV_32SC1);</b>
<b class="nc"><i>805</i>&nbsp;			IntIndexer idxResults = results.createIndexer();</b>
<i>806</i>&nbsp;			
<b class="nc"><i>807</i>&nbsp;			int[] orderedClasses = new int[nClasses];</b>
<b class="nc"><i>808</i>&nbsp;			for (int c = 0; c &lt; nClasses; c++) {</b>
<b class="nc"><i>809</i>&nbsp;				orderedClasses[c] = indexer.get(0, c);</b>
<i>810</i>&nbsp;			}
<b class="nc"><i>811</i>&nbsp;			long row = 1;</b>
<b class="nc"><i>812</i>&nbsp;			for (var i = 0; i &lt; nSamples; i++) {</b>
<b class="nc"><i>813</i>&nbsp;				double sum = 0;</b>
<b class="nc"><i>814</i>&nbsp;				int maxCount = -1;</b>
<b class="nc"><i>815</i>&nbsp;				int maxInd = -1;</b>
<b class="nc"><i>816</i>&nbsp;				for (long c = 0; c &lt; nClasses; c++) {</b>
<b class="nc"><i>817</i>&nbsp;					int count = indexer.get(row, c);</b>
<b class="nc"><i>818</i>&nbsp;					if (count &gt; maxCount) {</b>
<b class="nc"><i>819</i>&nbsp;						maxCount = count;</b>
<b class="nc"><i>820</i>&nbsp;						maxInd = (int)c;</b>
<i>821</i>&nbsp;					}
<b class="nc"><i>822</i>&nbsp;					sum += count;</b>
<i>823</i>&nbsp;				}
<i>824</i>&nbsp;				// Update probability estimates
<b class="nc"><i>825</i>&nbsp;				for (int c = 0; c &lt; nClasses; c++) {</b>
<b class="nc"><i>826</i>&nbsp;					int count = indexer.get(row, c);</b>
<b class="nc"><i>827</i>&nbsp;					idxProbabilities.put(i, orderedClasses[c], (float)(count / sum));</b>
<i>828</i>&nbsp;				}
<i>829</i>&nbsp;				// Update prediction
<b class="nc"><i>830</i>&nbsp;				int prediction = orderedClasses[maxInd];</b>
<b class="nc"><i>831</i>&nbsp;				idxResults.put(i, prediction);</b>
<b class="nc"><i>832</i>&nbsp;				row++;</b>
<i>833</i>&nbsp;			}
<b class="nc"><i>834</i>&nbsp;			votes.release();</b>
<i>835</i>&nbsp;		}
<i>836</i>&nbsp;		
<i>837</i>&nbsp;		
<i>838</i>&nbsp;	}
<i>839</i>&nbsp;	
<i>840</i>&nbsp;	/**
<i>841</i>&nbsp;	 * Classifier based on {@link Boost}.
<i>842</i>&nbsp;	 */
<i>843</i>&nbsp;	public static class BoostClassifier extends AbstractTreeClassifier&lt;Boost&gt; {
<i>844</i>&nbsp;		
<i>845</i>&nbsp;		BoostClassifier() {
<b class="nc"><i>846</i>&nbsp;			super();</b>
<i>847</i>&nbsp;		}
<i>848</i>&nbsp;		
<i>849</i>&nbsp;		BoostClassifier(final Boost model) {
<b class="nc"><i>850</i>&nbsp;			super(model);</b>
<i>851</i>&nbsp;		}
<i>852</i>&nbsp;
<i>853</i>&nbsp;		@Override
<i>854</i>&nbsp;		Boost createStatModel() {
<b class="nc"><i>855</i>&nbsp;			return Boost.create();</b>
<i>856</i>&nbsp;		}
<i>857</i>&nbsp;		
<i>858</i>&nbsp;		@Override
<i>859</i>&nbsp;		Class&lt;? extends StatModel&gt; getStatModelClass() {
<b class="nc"><i>860</i>&nbsp;			return Boost.class;</b>
<i>861</i>&nbsp;		}
<i>862</i>&nbsp;
<i>863</i>&nbsp;		
<i>864</i>&nbsp;		@Override
<i>865</i>&nbsp;		ParameterList createParameterList(Boost model) {
<b class="nc"><i>866</i>&nbsp;			ParameterList params = super.createParameterList(model);</b>
<i>867</i>&nbsp;			
<i>868</i>&nbsp;//			int boostType = model.getBoostType();
<b class="nc"><i>869</i>&nbsp;			var weakCount = model.getWeakCount();</b>
<b class="nc"><i>870</i>&nbsp;			double weightTrimRate = model.getWeightTrimRate();</b>
<i>871</i>&nbsp;			
<b class="nc"><i>872</i>&nbsp;			params.addIntParameter(&quot;weakCount&quot;, &quot;Number of weak classifiers&quot;, weakCount, null, &quot;Number of weak classifiers to train&quot;);</b>
<b class="nc"><i>873</i>&nbsp;			params.addDoubleParameter(&quot;weightTrimRate&quot;, &quot;Weight trim rate&quot;, weightTrimRate, null, 0, 1, &quot;Threshold used to save computational time&quot;);</b>
<i>874</i>&nbsp;			
<b class="nc"><i>875</i>&nbsp;			return params;</b>
<i>876</i>&nbsp;		}
<i>877</i>&nbsp;
<i>878</i>&nbsp;		@Override
<i>879</i>&nbsp;		void updateModel(Boost model, ParameterList params, TrainData trainData) {
<b class="nc"><i>880</i>&nbsp;			super.updateModel(model, params, trainData);</b>
<i>881</i>&nbsp;			
<b class="nc"><i>882</i>&nbsp;			int weakCount = params.getIntParameterValue(&quot;weakCount&quot;);</b>
<b class="nc"><i>883</i>&nbsp;			double weightTrimRate = params.getDoubleParameterValue(&quot;weightTrimRate&quot;);</b>
<i>884</i>&nbsp;			
<b class="nc"><i>885</i>&nbsp;			model.setWeakCount(weakCount);</b>
<b class="nc"><i>886</i>&nbsp;			model.setWeightTrimRate(weightTrimRate);</b>
<i>887</i>&nbsp;		}
<i>888</i>&nbsp;		
<i>889</i>&nbsp;	}
<i>890</i>&nbsp;	
<i>891</i>&nbsp;	/**
<i>892</i>&nbsp;	 * Classifier based on {@link LogisticRegression}.
<i>893</i>&nbsp;	 */
<i>894</i>&nbsp;	public static class LogisticRegressionClassifier extends AbstractOpenCVClassifierML&lt;LogisticRegression&gt; {
<i>895</i>&nbsp;		
<b class="nc"><i>896</i>&nbsp;		static enum Regularization {</b>
<b class="nc"><i>897</i>&nbsp;			DISABLE, L1, L2;</b>
<i>898</i>&nbsp;			
<i>899</i>&nbsp;			public int getRegularization() {
<b class="nc"><i>900</i>&nbsp;				switch(this) {</b>
<i>901</i>&nbsp;				case L1:
<b class="nc"><i>902</i>&nbsp;					return LogisticRegression.REG_L1;</b>
<i>903</i>&nbsp;				case L2:
<b class="nc"><i>904</i>&nbsp;					return LogisticRegression.REG_L2;</b>
<i>905</i>&nbsp;				case DISABLE:
<i>906</i>&nbsp;				default:
<b class="nc"><i>907</i>&nbsp;					return LogisticRegression.REG_DISABLE;</b>
<i>908</i>&nbsp;				}
<i>909</i>&nbsp;			}
<i>910</i>&nbsp;			
<i>911</i>&nbsp;			@Override
<i>912</i>&nbsp;			public String toString() {
<b class="nc"><i>913</i>&nbsp;				switch(this) {</b>
<i>914</i>&nbsp;				case L1:
<b class="nc"><i>915</i>&nbsp;					return &quot;L1&quot;;</b>
<i>916</i>&nbsp;				case L2:
<b class="nc"><i>917</i>&nbsp;					return &quot;L2&quot;;</b>
<i>918</i>&nbsp;				case DISABLE:
<i>919</i>&nbsp;				default:
<b class="nc"><i>920</i>&nbsp;					return &quot;None&quot;;</b>
<i>921</i>&nbsp;				}
<i>922</i>&nbsp;			}
<i>923</i>&nbsp;		}
<i>924</i>&nbsp;		
<i>925</i>&nbsp;		LogisticRegressionClassifier() {
<b class="nc"><i>926</i>&nbsp;			super();</b>
<i>927</i>&nbsp;		}
<i>928</i>&nbsp;		
<i>929</i>&nbsp;		LogisticRegressionClassifier(final LogisticRegression model) {
<b class="nc"><i>930</i>&nbsp;			super(model);</b>
<i>931</i>&nbsp;		}
<i>932</i>&nbsp;
<i>933</i>&nbsp;		@Override
<i>934</i>&nbsp;		ParameterList createParameterList(LogisticRegression model) {
<b class="nc"><i>935</i>&nbsp;			var params = new ParameterList();</b>
<b class="nc"><i>936</i>&nbsp;			double learningRate = model.getLearningRate();</b>
<b class="nc"><i>937</i>&nbsp;			int nIterations = model.getIterations();</b>
<b class="nc"><i>938</i>&nbsp;			int reg = model.getRegularization();</b>
<b class="nc"><i>939</i>&nbsp;			Regularization defaultReg = Regularization.DISABLE;</b>
<b class="nc"><i>940</i>&nbsp;			for (Regularization temp : Regularization.values()) {</b>
<b class="nc"><i>941</i>&nbsp;				if (reg == temp.getRegularization()) {</b>
<b class="nc"><i>942</i>&nbsp;					defaultReg = temp;</b>
<b class="nc"><i>943</i>&nbsp;					break;</b>
<i>944</i>&nbsp;				}
<i>945</i>&nbsp;			}
<i>946</i>&nbsp;//			int miniBatchSize = model.getMiniBatchSize();
<i>947</i>&nbsp;			
<b class="nc"><i>948</i>&nbsp;			params.addTitleParameter(&quot;Logistic regression options&quot;);</b>
<b class="nc"><i>949</i>&nbsp;			params.addDoubleParameter(&quot;learningRate&quot;, &quot;Learning rate&quot;, learningRate);</b>
<b class="nc"><i>950</i>&nbsp;			params.addIntParameter(&quot;nIterations&quot;, &quot;Number of iterations&quot;, nIterations);</b>
<i>951</i>&nbsp;//			params.addIntParameter(&quot;miniBatchSize&quot;, &quot;Mini batch size&quot;, miniBatchSize);
<b class="nc"><i>952</i>&nbsp;			params.addChoiceParameter(&quot;regularization&quot;, &quot;Regularization&quot;, defaultReg, Arrays.asList(Regularization.values()));</b>
<i>953</i>&nbsp;			
<b class="nc"><i>954</i>&nbsp;			addTerminationCriteriaParameters(params, model.getTermCriteria());</b>
<b class="nc"><i>955</i>&nbsp;			return params;</b>
<i>956</i>&nbsp;		}
<i>957</i>&nbsp;		
<i>958</i>&nbsp;		@Override
<i>959</i>&nbsp;		public TrainData createTrainData(Mat samples, Mat targets, Mat weights, boolean doMulticlass) {
<b class="nc"><i>960</i>&nbsp;			targets.convertTo(targets, opencv_core.CV_32F);</b>
<b class="nc"><i>961</i>&nbsp;			return super.createTrainData(samples, targets, weights, doMulticlass);</b>
<i>962</i>&nbsp;		}
<i>963</i>&nbsp;
<i>964</i>&nbsp;		@Override
<i>965</i>&nbsp;		LogisticRegression createStatModel() {
<b class="nc"><i>966</i>&nbsp;			return LogisticRegression.create();</b>
<i>967</i>&nbsp;		}
<i>968</i>&nbsp;
<i>969</i>&nbsp;		@Override
<i>970</i>&nbsp;		Class&lt;? extends StatModel&gt; getStatModelClass() {
<b class="nc"><i>971</i>&nbsp;			return LogisticRegression.class;</b>
<i>972</i>&nbsp;		}
<i>973</i>&nbsp;		
<i>974</i>&nbsp;		@Override
<i>975</i>&nbsp;		void updateModel(LogisticRegression model, ParameterList params, TrainData trainData) {
<b class="nc"><i>976</i>&nbsp;			double learningRate = params.getDoubleParameterValue(&quot;learningRate&quot;);</b>
<b class="nc"><i>977</i>&nbsp;			int nIterations = params.getIntParameterValue(&quot;nIterations&quot;);</b>
<b class="nc"><i>978</i>&nbsp;			Regularization regularization = (Regularization)params.getChoiceParameterValue(&quot;regularization&quot;);</b>
<b class="nc"><i>979</i>&nbsp;			model.setRegularization(regularization.getRegularization());</b>
<i>980</i>&nbsp;			
<b class="nc"><i>981</i>&nbsp;			model.setLearningRate(learningRate);</b>
<b class="nc"><i>982</i>&nbsp;			model.setIterations(nIterations);</b>
<i>983</i>&nbsp;			
<b class="nc"><i>984</i>&nbsp;			model.setTermCriteria(updateTermCriteria(params, model.getTermCriteria()));</b>
<i>985</i>&nbsp;		}
<i>986</i>&nbsp;		
<i>987</i>&nbsp;	}
<i>988</i>&nbsp;	
<i>989</i>&nbsp;	
<i>990</i>&nbsp;	/**
<i>991</i>&nbsp;	 * Classifier based on {@link NormalBayesClassifier}.
<i>992</i>&nbsp;	 */
<i>993</i>&nbsp;	public static class NormalBayesClassifierCV extends AbstractOpenCVClassifierML&lt;NormalBayesClassifier&gt; {
<i>994</i>&nbsp;
<i>995</i>&nbsp;		NormalBayesClassifierCV() {
<b class="nc"><i>996</i>&nbsp;			super();</b>
<i>997</i>&nbsp;		}
<i>998</i>&nbsp;		
<i>999</i>&nbsp;		NormalBayesClassifierCV(final NormalBayesClassifier model) {
<b class="nc"><i>1000</i>&nbsp;			super(model);</b>
<i>1001</i>&nbsp;		}
<i>1002</i>&nbsp;		
<i>1003</i>&nbsp;		@Override
<i>1004</i>&nbsp;		ParameterList createParameterList(NormalBayesClassifier model) {
<b class="nc"><i>1005</i>&nbsp;			var params = new ParameterList();</b>
<b class="nc"><i>1006</i>&nbsp;			params.addTitleParameter(&quot;No parameters to adjust!&quot;);</b>
<b class="nc"><i>1007</i>&nbsp;			return params;</b>
<i>1008</i>&nbsp;		}
<i>1009</i>&nbsp;
<i>1010</i>&nbsp;		@Override
<i>1011</i>&nbsp;		NormalBayesClassifier createStatModel() {
<b class="nc"><i>1012</i>&nbsp;			return NormalBayesClassifier.create();</b>
<i>1013</i>&nbsp;		}
<i>1014</i>&nbsp;		
<i>1015</i>&nbsp;		@Override
<i>1016</i>&nbsp;		Class&lt;? extends StatModel&gt; getStatModelClass() {
<b class="nc"><i>1017</i>&nbsp;			return NormalBayesClassifier.class;</b>
<i>1018</i>&nbsp;		}
<i>1019</i>&nbsp;
<i>1020</i>&nbsp;		@Override
<i>1021</i>&nbsp;		void updateModel(NormalBayesClassifier model, ParameterList params, TrainData trainData) {}
<i>1022</i>&nbsp;		
<i>1023</i>&nbsp;		@Override
<i>1024</i>&nbsp;		public void predictWithLock(Mat samples, Mat results, Mat probabilities) {
<b class="nc"><i>1025</i>&nbsp;			var model = getStatModel();</b>
<b class="nc"><i>1026</i>&nbsp;			if (probabilities == null)</b>
<b class="nc"><i>1027</i>&nbsp;				probabilities = new Mat();</b>
<b class="nc"><i>1028</i>&nbsp;			model.predictProb(samples, results, probabilities, 0);</b>
<i>1029</i>&nbsp;		}
<i>1030</i>&nbsp;	}
<i>1031</i>&nbsp;	
<i>1032</i>&nbsp;	/**
<i>1033</i>&nbsp;	 * Clusterer based on {@link EM}.
<i>1034</i>&nbsp;	 */
<i>1035</i>&nbsp;	public static class EMClusterer extends AbstractOpenCVClassifierML&lt;EM&gt; {
<i>1036</i>&nbsp;		
<i>1037</i>&nbsp;		EMClusterer() {
<b class="nc"><i>1038</i>&nbsp;			super();</b>
<i>1039</i>&nbsp;		}
<i>1040</i>&nbsp;		
<i>1041</i>&nbsp;		EMClusterer(final EM model) {
<b class="nc"><i>1042</i>&nbsp;			super(model);</b>
<i>1043</i>&nbsp;		}
<i>1044</i>&nbsp;
<i>1045</i>&nbsp;		@Override
<i>1046</i>&nbsp;		ParameterList createParameterList(EM model) {
<b class="nc"><i>1047</i>&nbsp;			var params = new ParameterList();</b>
<i>1048</i>&nbsp;			
<b class="nc"><i>1049</i>&nbsp;			int nClusters = model.getClustersNumber();</b>
<b class="nc"><i>1050</i>&nbsp;			params.addIntParameter(&quot;nClusters&quot;, &quot;Number of clusters&quot;, nClusters);</b>
<i>1051</i>&nbsp;			
<b class="nc"><i>1052</i>&nbsp;			return params;</b>
<i>1053</i>&nbsp;		}
<i>1054</i>&nbsp;
<i>1055</i>&nbsp;		@Override
<i>1056</i>&nbsp;		Class&lt;? extends StatModel&gt; getStatModelClass() {
<b class="nc"><i>1057</i>&nbsp;			return EM.class;</b>
<i>1058</i>&nbsp;		}
<i>1059</i>&nbsp;
<i>1060</i>&nbsp;		
<i>1061</i>&nbsp;		@Override
<i>1062</i>&nbsp;		EM createStatModel() {
<b class="nc"><i>1063</i>&nbsp;			return EM.create();</b>
<i>1064</i>&nbsp;		}
<i>1065</i>&nbsp;
<i>1066</i>&nbsp;		@Override
<i>1067</i>&nbsp;		void updateModel(EM model, ParameterList params, TrainData trainData) {
<b class="nc"><i>1068</i>&nbsp;			model.setClustersNumber(params.getIntParameterValue(&quot;nClusters&quot;));</b>
<i>1069</i>&nbsp;		}
<i>1070</i>&nbsp;		
<i>1071</i>&nbsp;	}
<i>1072</i>&nbsp;	
<i>1073</i>&nbsp;	/**
<i>1074</i>&nbsp;	 * Classifier based on {@link SVM}.
<i>1075</i>&nbsp;	 */
<i>1076</i>&nbsp;	public static class SVMClassifierCV extends AbstractOpenCVClassifierML&lt;SVM&gt; {
<i>1077</i>&nbsp;
<i>1078</i>&nbsp;		SVMClassifierCV() {
<b class="nc"><i>1079</i>&nbsp;			super();</b>
<i>1080</i>&nbsp;		}
<i>1081</i>&nbsp;		
<i>1082</i>&nbsp;		SVMClassifierCV(final SVM model) {
<b class="nc"><i>1083</i>&nbsp;			super(model);</b>
<i>1084</i>&nbsp;		}
<i>1085</i>&nbsp;		
<i>1086</i>&nbsp;		@Override
<i>1087</i>&nbsp;		ParameterList createParameterList(SVM model) {
<b class="nc"><i>1088</i>&nbsp;			var params = new ParameterList();</b>
<b class="nc"><i>1089</i>&nbsp;			return params;</b>
<i>1090</i>&nbsp;		}
<i>1091</i>&nbsp;
<i>1092</i>&nbsp;		@Override
<i>1093</i>&nbsp;		SVM createStatModel() {
<b class="nc"><i>1094</i>&nbsp;			return SVM.create();</b>
<i>1095</i>&nbsp;		}
<i>1096</i>&nbsp;		
<i>1097</i>&nbsp;		@Override
<i>1098</i>&nbsp;		public boolean supportsAutoUpdate() {
<b class="nc"><i>1099</i>&nbsp;			return false;</b>
<i>1100</i>&nbsp;		}
<i>1101</i>&nbsp;		
<i>1102</i>&nbsp;		@Override
<i>1103</i>&nbsp;		Class&lt;? extends StatModel&gt; getStatModelClass() {
<b class="nc"><i>1104</i>&nbsp;			return SVM.class;</b>
<i>1105</i>&nbsp;		}
<i>1106</i>&nbsp;
<i>1107</i>&nbsp;		@Override
<i>1108</i>&nbsp;		void updateModel(SVM model, ParameterList params, TrainData trainData) {
<i>1109</i>&nbsp;			// TODO Auto-generated method stub
<i>1110</i>&nbsp;		}
<i>1111</i>&nbsp;		
<i>1112</i>&nbsp;	}
<i>1113</i>&nbsp;	
<i>1114</i>&nbsp;	/**
<i>1115</i>&nbsp;	 * Classifier based on {@link SVMSGD}.
<i>1116</i>&nbsp;	 */
<i>1117</i>&nbsp;	public static class SVMSGDClassifierCV extends AbstractOpenCVClassifierML&lt;SVMSGD&gt; {
<i>1118</i>&nbsp;
<i>1119</i>&nbsp;		SVMSGDClassifierCV() {
<b class="nc"><i>1120</i>&nbsp;			super();</b>
<i>1121</i>&nbsp;		}
<i>1122</i>&nbsp;		
<i>1123</i>&nbsp;		SVMSGDClassifierCV(final SVMSGD model) {
<b class="nc"><i>1124</i>&nbsp;			super(model);</b>
<i>1125</i>&nbsp;		}
<i>1126</i>&nbsp;		
<i>1127</i>&nbsp;		@Override
<i>1128</i>&nbsp;		ParameterList createParameterList(SVMSGD model) {
<b class="nc"><i>1129</i>&nbsp;			var params = new ParameterList();</b>
<b class="nc"><i>1130</i>&nbsp;			return params;</b>
<i>1131</i>&nbsp;		}
<i>1132</i>&nbsp;
<i>1133</i>&nbsp;		@Override
<i>1134</i>&nbsp;		SVMSGD createStatModel() {
<b class="nc"><i>1135</i>&nbsp;			return SVMSGD.create();</b>
<i>1136</i>&nbsp;		}
<i>1137</i>&nbsp;		
<i>1138</i>&nbsp;		@Override
<i>1139</i>&nbsp;		Class&lt;? extends StatModel&gt; getStatModelClass() {
<b class="nc"><i>1140</i>&nbsp;			return SVMSGD.class;</b>
<i>1141</i>&nbsp;		}
<i>1142</i>&nbsp;		
<i>1143</i>&nbsp;		@Override
<i>1144</i>&nbsp;		public boolean supportsAutoUpdate() {
<b class="nc"><i>1145</i>&nbsp;			return false;</b>
<i>1146</i>&nbsp;		}
<i>1147</i>&nbsp;
<i>1148</i>&nbsp;		@Override
<i>1149</i>&nbsp;		void updateModel(SVMSGD model, ParameterList params, TrainData trainData) {
<i>1150</i>&nbsp;			// TODO Auto-generated method stub
<i>1151</i>&nbsp;		}
<i>1152</i>&nbsp;		
<i>1153</i>&nbsp;	}
<i>1154</i>&nbsp;	
<i>1155</i>&nbsp;	/**
<i>1156</i>&nbsp;	 * Classifier based on {@link KNearest}.
<i>1157</i>&nbsp;	 */
<i>1158</i>&nbsp;	static class KNearestClassifierCV extends AbstractOpenCVClassifierML&lt;KNearest&gt; {
<i>1159</i>&nbsp;
<i>1160</i>&nbsp;		KNearestClassifierCV() {
<b class="nc"><i>1161</i>&nbsp;			super();</b>
<i>1162</i>&nbsp;		}
<i>1163</i>&nbsp;		
<i>1164</i>&nbsp;		KNearestClassifierCV(final KNearest model) {
<b class="nc"><i>1165</i>&nbsp;			super(model);</b>
<i>1166</i>&nbsp;		}
<i>1167</i>&nbsp;		
<i>1168</i>&nbsp;		@Override
<i>1169</i>&nbsp;		ParameterList createParameterList(KNearest model) {
<b class="nc"><i>1170</i>&nbsp;			var params = new ParameterList();</b>
<b class="nc"><i>1171</i>&nbsp;			int defaultK = model.getDefaultK();</b>
<b class="nc"><i>1172</i>&nbsp;			params.addIntParameter(&quot;defaultK&quot;, &quot;Default K&quot;, defaultK, null, &quot;Number of nearest neighbors&quot;);</b>
<b class="nc"><i>1173</i>&nbsp;			return params;</b>
<i>1174</i>&nbsp;		}
<i>1175</i>&nbsp;
<i>1176</i>&nbsp;		@Override
<i>1177</i>&nbsp;		KNearest createStatModel() {
<b class="nc"><i>1178</i>&nbsp;			return KNearest.create();</b>
<i>1179</i>&nbsp;		}
<i>1180</i>&nbsp;		
<i>1181</i>&nbsp;		@Override
<i>1182</i>&nbsp;		Class&lt;? extends StatModel&gt; getStatModelClass() {
<b class="nc"><i>1183</i>&nbsp;			return KNearest.class;</b>
<i>1184</i>&nbsp;		}
<i>1185</i>&nbsp;
<i>1186</i>&nbsp;		@Override
<i>1187</i>&nbsp;		void updateModel(KNearest model, ParameterList params, TrainData trainData) {
<b class="nc"><i>1188</i>&nbsp;			int defaultK = params.getIntParameterValue(&quot;defaultK&quot;);</b>
<b class="nc"><i>1189</i>&nbsp;			model.setDefaultK(defaultK);</b>
<b class="nc"><i>1190</i>&nbsp;			model.setIsClassifier(true);</b>
<i>1191</i>&nbsp;		}
<i>1192</i>&nbsp;		
<i>1193</i>&nbsp;	}
<i>1194</i>&nbsp;	
<i>1195</i>&nbsp;	/**
<i>1196</i>&nbsp;	 * Classifier based on {@link ANN_MLP}.
<i>1197</i>&nbsp;	 */
<i>1198</i>&nbsp;	static class ANNClassifierCV extends AbstractOpenCVClassifierML&lt;ANN_MLP&gt; {
<i>1199</i>&nbsp;		
<b class="nc"><i>1200</i>&nbsp;		private static Logger logger = LoggerFactory.getLogger(ANNClassifierCV.class);</b>
<i>1201</i>&nbsp;		
<b class="nc"><i>1202</i>&nbsp;		private int MAX_HIDDEN_LAYERS = 5;</b>
<i>1203</i>&nbsp;		
<b class="nc"><i>1204</i>&nbsp;		static enum ActivationFunction {</b>
<b class="nc"><i>1205</i>&nbsp;			IDENTITY, SIGMOID_SYM, GAUSSIAN, RELU, LEAKY_RELU;</b>
<i>1206</i>&nbsp;			
<i>1207</i>&nbsp;			public int getActivationFunction() {
<b class="nc"><i>1208</i>&nbsp;				switch(this) {</b>
<i>1209</i>&nbsp;				case GAUSSIAN:
<b class="nc"><i>1210</i>&nbsp;					return ANN_MLP.GAUSSIAN;</b>
<i>1211</i>&nbsp;				case IDENTITY:
<b class="nc"><i>1212</i>&nbsp;					return ANN_MLP.IDENTITY;</b>
<i>1213</i>&nbsp;				case SIGMOID_SYM:
<b class="nc"><i>1214</i>&nbsp;					return ANN_MLP.SIGMOID_SYM;</b>
<i>1215</i>&nbsp;				case RELU:
<b class="nc"><i>1216</i>&nbsp;					return ANN_MLP.RELU;</b>
<i>1217</i>&nbsp;				case LEAKY_RELU:
<b class="nc"><i>1218</i>&nbsp;					return ANN_MLP.LEAKYRELU;</b>
<i>1219</i>&nbsp;				default:
<b class="nc"><i>1220</i>&nbsp;					return ANN_MLP.SIGMOID_SYM;</b>
<i>1221</i>&nbsp;				}
<i>1222</i>&nbsp;			}
<i>1223</i>&nbsp;		}
<i>1224</i>&nbsp;		
<b class="nc"><i>1225</i>&nbsp;		static enum TrainingMethod {</b>
<b class="nc"><i>1226</i>&nbsp;			BACKPROP, RPROP, ANNEAL;</b>
<i>1227</i>&nbsp;			
<i>1228</i>&nbsp;			public int getTrainingMethod() {
<b class="nc"><i>1229</i>&nbsp;				switch(this) {</b>
<i>1230</i>&nbsp;				case BACKPROP:
<b class="nc"><i>1231</i>&nbsp;					return ANN_MLP.BACKPROP;</b>
<i>1232</i>&nbsp;				case RPROP:
<b class="nc"><i>1233</i>&nbsp;					return ANN_MLP.RPROP;</b>
<i>1234</i>&nbsp;				case ANNEAL:
<b class="nc"><i>1235</i>&nbsp;					return ANN_MLP.ANNEAL;</b>
<i>1236</i>&nbsp;				default:
<b class="nc"><i>1237</i>&nbsp;					return ANN_MLP.BACKPROP;</b>
<i>1238</i>&nbsp;				}
<i>1239</i>&nbsp;			}
<i>1240</i>&nbsp;		}
<i>1241</i>&nbsp;		
<i>1242</i>&nbsp;		
<i>1243</i>&nbsp;		ANNClassifierCV() {
<b class="nc"><i>1244</i>&nbsp;			super();</b>
<i>1245</i>&nbsp;		}
<i>1246</i>&nbsp;		
<i>1247</i>&nbsp;		ANNClassifierCV(final ANN_MLP model) {
<b class="nc"><i>1248</i>&nbsp;			super(model);</b>
<i>1249</i>&nbsp;		}
<i>1250</i>&nbsp;
<i>1251</i>&nbsp;		@Override
<i>1252</i>&nbsp;		ParameterList createParameterList(ANN_MLP model) {
<i>1253</i>&nbsp;			// Parse existing layer sizes, if we have them
<b class="nc"><i>1254</i>&nbsp;			Mat sizes = model.getLayerSizes();</b>
<i>1255</i>&nbsp;			int[] layerSizes;
<b class="nc"><i>1256</i>&nbsp;			if (!sizes.empty()) {</b>
<b class="nc"><i>1257</i>&nbsp;				var idx = sizes.createIndexer();</b>
<b class="nc"><i>1258</i>&nbsp;				int n = (int)sizes.total();</b>
<b class="nc"><i>1259</i>&nbsp;				layerSizes = new int[n];</b>
<b class="nc"><i>1260</i>&nbsp;				for (int i = 0; i &lt; n; i++)</b>
<b class="nc"><i>1261</i>&nbsp;					layerSizes[i] = (int)idx.getDouble(i);</b>
<b class="nc"><i>1262</i>&nbsp;				idx.release();</b>
<b class="nc"><i>1263</i>&nbsp;				MAX_HIDDEN_LAYERS = n;</b>
<b class="nc"><i>1264</i>&nbsp;			} else {</b>
<b class="nc"><i>1265</i>&nbsp;				layerSizes = new int[MAX_HIDDEN_LAYERS];</b>
<i>1266</i>&nbsp;			}
<i>1267</i>&nbsp;			
<i>1268</i>&nbsp;			
<b class="nc"><i>1269</i>&nbsp;			var params = new ParameterList();</b>
<i>1270</i>&nbsp;			
<i>1271</i>&nbsp;//			// Set activation function
<i>1272</i>&nbsp;//			params.addTitleParameter(&quot;Activation&quot;);
<i>1273</i>&nbsp;//			params.addChoiceParameter(&quot;activation&quot;, &quot;Activation function&quot;, ActivationFunction.SIGMOID_SYM,
<i>1274</i>&nbsp;//					Arrays.asList(ActivationFunction.values()), &quot;Choose activation function (only SIGMOID_SYM is fully supported)&quot;);
<i>1275</i>&nbsp;//			params.addDoubleParameter(&quot;activationAlpha&quot;, &quot;Alpha&quot;, 1, null, &quot;Alpha value (influences &#39;steepness&#39;)&quot;);
<i>1276</i>&nbsp;//			params.addDoubleParameter(&quot;activationBeta&quot;, &quot;Beta&quot;, 1, null, &quot;Alpha value (influences &#39;range&#39;)&quot;);
<i>1277</i>&nbsp;			
<i>1278</i>&nbsp;//			// Set train method
<i>1279</i>&nbsp;//			params.addTitleParameter(&quot;Training method&quot;);
<i>1280</i>&nbsp;//			params.addChoiceParameter(&quot;trainMethod&quot;, &quot;Training method&quot;, TrainingMethod.RPROP,
<i>1281</i>&nbsp;//					Arrays.asList(TrainingMethod.values()), &quot;Choose training method&quot;);
<i>1282</i>&nbsp;//			params.addDoubleParameter(&quot;trainParam1&quot;, &quot;Training parameter 1&quot;, model.getRpropDW0(), null, &quot;Passed to either setRpropDW0 or setBackpropWeightScale&quot;);
<i>1283</i>&nbsp;//			params.addDoubleParameter(&quot;trainParam2&quot;, &quot;Training parameter 2&quot;, model.getRpropDWMin(), null, &quot;Passed to either setRpropDWMin or setBackpropMomentumScale&quot;);
<i>1284</i>&nbsp;			
<i>1285</i>&nbsp;			// Hidden layer sizes
<b class="nc"><i>1286</i>&nbsp;			params.addTitleParameter(&quot;Hidden layers&quot;);</b>
<b class="nc"><i>1287</i>&nbsp;			for (int i = 1; i &lt;= layerSizes.length; i++) {</b>
<b class="nc"><i>1288</i>&nbsp;				params.addIntParameter(&quot;hidden&quot; + i, &quot;Layer &quot; + i, layerSizes[i-1], &quot;Nodes&quot;, &quot;Size of first hidden layer (0 to omit layer)&quot;);				</b>
<i>1289</i>&nbsp;			}
<i>1290</i>&nbsp;			
<b class="nc"><i>1291</i>&nbsp;			addTerminationCriteriaParameters(params, model.getTermCriteria());</b>
<i>1292</i>&nbsp;
<b class="nc"><i>1293</i>&nbsp;			return params;</b>
<i>1294</i>&nbsp;		}
<i>1295</i>&nbsp;		
<i>1296</i>&nbsp;		@Override
<i>1297</i>&nbsp;		protected int getTrainFlags() {
<b class="nc"><i>1298</i>&nbsp;			return ANN_MLP.NO_OUTPUT_SCALE;</b>
<i>1299</i>&nbsp;		}
<i>1300</i>&nbsp;
<i>1301</i>&nbsp;		@Override
<i>1302</i>&nbsp;		ANN_MLP createStatModel() {
<b class="nc"><i>1303</i>&nbsp;			return ANN_MLP.create();</b>
<i>1304</i>&nbsp;		}
<i>1305</i>&nbsp;		
<i>1306</i>&nbsp;		@Override
<i>1307</i>&nbsp;		Class&lt;? extends StatModel&gt; getStatModelClass() {
<b class="nc"><i>1308</i>&nbsp;			return ANN_MLP.class;</b>
<i>1309</i>&nbsp;		}
<i>1310</i>&nbsp;		
<i>1311</i>&nbsp;		// This shows how to potentially re-weight training samples
<i>1312</i>&nbsp;//		@Override
<i>1313</i>&nbsp;//		public void trainWithLock(TrainData trainData) {
<i>1314</i>&nbsp;//			var statModel = getStatModel();
<i>1315</i>&nbsp;//			updateModel(statModel, getParameterList(), trainData);
<i>1316</i>&nbsp;//			statModel.train(trainData, getTrainFlags());
<i>1317</i>&nbsp;//			
<i>1318</i>&nbsp;//			// Retrain
<i>1319</i>&nbsp;//			 Mat results = new Mat();
<i>1320</i>&nbsp;//			 Mat probabilities = new Mat();
<i>1321</i>&nbsp;//			 var samples = trainData.getTrainSamples();
<i>1322</i>&nbsp;//			 var targets = trainData.getTrainResponses();
<i>1323</i>&nbsp;//			 long n = samples.rows();
<i>1324</i>&nbsp;//			 Mat weights = new Mat((int)n, 1, opencv_core.CV_32FC1);
<i>1325</i>&nbsp;//			 FloatIndexer idxTargets = targets.createIndexer();
<i>1326</i>&nbsp;//			 for (int i = 0; i &lt; 5; i++) {
<i>1327</i>&nbsp;//				 predictWithLock(samples, results, probabilities);
<i>1328</i>&nbsp;//				 
<i>1329</i>&nbsp;//				 IntIndexer idxResults = results.createIndexer();
<i>1330</i>&nbsp;//				 FloatIndexer idxProbabilities = probabilities.createIndexer();
<i>1331</i>&nbsp;//				 FloatIndexer idxWeights = weights.createIndexer();
<i>1332</i>&nbsp;//				 int correct = 0;
<i>1333</i>&nbsp;//				 for (long j = 0; j &lt; n; j++) {
<i>1334</i>&nbsp;//					 int col = idxResults.get(j);
<i>1335</i>&nbsp;//					 double pt = idxProbabilities.get(j, col);
<i>1336</i>&nbsp;//					 boolean isCorrect = idxTargets.get(j, col) == 1f;
<i>1337</i>&nbsp;//					 if (isCorrect) {
<i>1338</i>&nbsp;//						 correct++;
<i>1339</i>&nbsp;//					 } else {
<i>1340</i>&nbsp;//						 pt = 1 - pt;
<i>1341</i>&nbsp;//					 }
<i>1342</i>&nbsp;//					 // TODO: Calculate weights in a smarter way!
<i>1343</i>&nbsp;//					 double weight = 1-Math.log(Math.max(pt, 0.1));
<i>1344</i>&nbsp;//					 idxWeights.put(j, (float)weight);
<i>1345</i>&nbsp;//				 }
<i>1346</i>&nbsp;//				 System.err.println(String.format(&quot;Correct: %.2f %%&quot;, correct * 100.0 / n));
<i>1347</i>&nbsp;//				 idxResults.release();
<i>1348</i>&nbsp;//				 idxProbabilities.release();
<i>1349</i>&nbsp;//				 idxWeights.release();
<i>1350</i>&nbsp;//				 
<i>1351</i>&nbsp;//			 	 trainData = TrainData.create(
<i>1352</i>&nbsp;//			 			samples,
<i>1353</i>&nbsp;//			 			 trainData.getLayout(),
<i>1354</i>&nbsp;//			 			 targets,
<i>1355</i>&nbsp;//			 			 new Mat(),
<i>1356</i>&nbsp;//			 			 new Mat(),
<i>1357</i>&nbsp;//			 			weights,
<i>1358</i>&nbsp;//			 			 trainData.getVarType());
<i>1359</i>&nbsp;//			 	 statModel.train(trainData, getTrainFlags() + ANN_MLP.UPDATE_WEIGHTS);
<i>1360</i>&nbsp;//			 }
<i>1361</i>&nbsp;//		}
<i>1362</i>&nbsp;
<i>1363</i>&nbsp;		
<i>1364</i>&nbsp;		@Override
<i>1365</i>&nbsp;		public TrainData createTrainData(Mat samples, Mat targets, Mat weights, boolean doMulticlass) {
<b class="nc"><i>1366</i>&nbsp;			if (doMulticlass) {</b>
<b class="nc"><i>1367</i>&nbsp;				var indexer = targets.createIndexer();</b>
<b class="nc"><i>1368</i>&nbsp;				var targets2 = new Mat(targets.rows(), targets.cols(), opencv_core.CV_32FC1, Scalar.all(-1.0));</b>
<b class="nc"><i>1369</i>&nbsp;				FloatIndexer idxTargets = targets2.createIndexer();</b>
<b class="nc"><i>1370</i>&nbsp;				int nRows = targets.rows();</b>
<b class="nc"><i>1371</i>&nbsp;				int nCols = targets.cols();</b>
<b class="nc"><i>1372</i>&nbsp;				long[] inds = new long[2];</b>
<b class="nc"><i>1373</i>&nbsp;				for (int r = 0; r &lt; nRows; r++) {</b>
<b class="nc"><i>1374</i>&nbsp;					for (int c = 0; c &lt; nCols; c++) {</b>
<b class="nc"><i>1375</i>&nbsp;						inds[0] = r;</b>
<b class="nc"><i>1376</i>&nbsp;						inds[1] = c;</b>
<b class="nc"><i>1377</i>&nbsp;						double val = indexer.getDouble(inds);</b>
<b class="nc"><i>1378</i>&nbsp;						if (val &gt; 0)</b>
<b class="nc"><i>1379</i>&nbsp;							idxTargets.put(inds, 1f);</b>
<i>1380</i>&nbsp;					}
<i>1381</i>&nbsp;				}
<b class="nc"><i>1382</i>&nbsp;				targets.put(targets2);</b>
<b class="nc"><i>1383</i>&nbsp;				targets2.close();</b>
<b class="nc"><i>1384</i>&nbsp;			} else {</b>
<b class="nc"><i>1385</i>&nbsp;				IntBuffer buffer = targets.createBuffer();</b>
<b class="nc"><i>1386</i>&nbsp;				int[] vals = new int[targets.rows()];</b>
<b class="nc"><i>1387</i>&nbsp;				buffer.get(vals);</b>
<b class="nc"><i>1388</i>&nbsp;				int max = Arrays.stream(vals).max().orElseGet(() -&gt; 0) + 1;</b>
<b class="nc"><i>1389</i>&nbsp;				var targets2 = new Mat(targets.rows(), max, opencv_core.CV_32FC1, Scalar.all(-1.0));</b>
<b class="nc"><i>1390</i>&nbsp;				FloatIndexer idxTargets = targets2.createIndexer();</b>
<b class="nc"><i>1391</i>&nbsp;				int row = 0;</b>
<b class="nc"><i>1392</i>&nbsp;				for (var v : vals) {</b>
<b class="nc"><i>1393</i>&nbsp;					idxTargets.put(row, v, 1f);</b>
<b class="nc"><i>1394</i>&nbsp;					row++;</b>
<i>1395</i>&nbsp;				}
<b class="nc"><i>1396</i>&nbsp;				targets.put(targets2);</b>
<b class="nc"><i>1397</i>&nbsp;				targets2.close();</b>
<i>1398</i>&nbsp;			}
<i>1399</i>&nbsp;			
<b class="nc"><i>1400</i>&nbsp;			return super.createTrainData(samples, targets, weights, doMulticlass);</b>
<i>1401</i>&nbsp;		}
<i>1402</i>&nbsp;		
<i>1403</i>&nbsp;		
<i>1404</i>&nbsp;		@Override
<i>1405</i>&nbsp;		public void predictWithLock(Mat samples, Mat results, Mat probabilities) {
<i>1406</i>&nbsp;			// Extract parameters
<i>1407</i>&nbsp;//			var params = getParameterList();
<i>1408</i>&nbsp;//			var activation = (ActivationFunction)params.getChoiceParameterValue(&quot;activation&quot;);
<i>1409</i>&nbsp;//			double beta = params.getDoubleParameterValue(&quot;activationBeta&quot;);
<i>1410</i>&nbsp;			
<i>1411</i>&nbsp;			// For now, we only support SIGMOID_SYM as an activation function
<i>1412</i>&nbsp;			// (Not least because we must save/reload models, and there is not get method for this)
<b class="nc"><i>1413</i>&nbsp;			boolean isSigmoidSym = true;</b>
<b class="nc"><i>1414</i>&nbsp;			double beta = 1.0;</b>
<i>1415</i>&nbsp;			
<i>1416</i>&nbsp;			// Compute raw values
<b class="nc"><i>1417</i>&nbsp;			if (probabilities == null)</b>
<b class="nc"><i>1418</i>&nbsp;				probabilities = new Mat();</b>
<b class="nc"><i>1419</i>&nbsp;			super.predictWithLock(samples, results, probabilities);</b>
<i>1420</i>&nbsp;			
<i>1421</i>&nbsp;			// Convert to the range 0-1 if we can
<b class="nc"><i>1422</i>&nbsp;			if (isSigmoidSym) {</b>
<i>1423</i>&nbsp;						
<b class="nc"><i>1424</i>&nbsp;				var indexer = probabilities.createIndexer();</b>
<b class="nc"><i>1425</i>&nbsp;				long[] inds = new long[2];</b>
<b class="nc"><i>1426</i>&nbsp;				long rows = indexer.size(0); // previously .rows()</b>
<b class="nc"><i>1427</i>&nbsp;				long cols = indexer.size(1); // previously .cols()</b>
<b class="nc"><i>1428</i>&nbsp;				double scale = 0.5 / beta;</b>
<b class="nc"><i>1429</i>&nbsp;				double offset = 0.5;</b>
<i>1430</i>&nbsp;						
<b class="nc"><i>1431</i>&nbsp;				for (long r = 0; r &lt; rows; r++) {</b>
<b class="nc"><i>1432</i>&nbsp;					inds[0] = r;</b>
<i>1433</i>&nbsp;	//				double max = 0;
<b class="nc"><i>1434</i>&nbsp;					for (long c = 0; c &lt; cols; c++) {</b>
<b class="nc"><i>1435</i>&nbsp;						inds[1] = c;</b>
<b class="nc"><i>1436</i>&nbsp;						double val = indexer.getDouble(inds) * scale + offset;</b>
<i>1437</i>&nbsp;	//					val = val &gt; 1 ? 1 : val;
<i>1438</i>&nbsp;	//					val = val &lt; 0 ? 0 : val;
<b class="nc"><i>1439</i>&nbsp;						indexer.putDouble(inds, val);</b>
<i>1440</i>&nbsp;	//					max = Math.max(max, val);
<i>1441</i>&nbsp;					}
<i>1442</i>&nbsp;				}
<b class="nc"><i>1443</i>&nbsp;				indexer.release();</b>
<i>1444</i>&nbsp;			}
<i>1445</i>&nbsp;			// TODO: Consider softmax for identity or relu activations
<i>1446</i>&nbsp;		}
<i>1447</i>&nbsp;
<i>1448</i>&nbsp;		@Override
<i>1449</i>&nbsp;		void updateModel(ANN_MLP model, ParameterList params, TrainData trainData) {
<b class="nc"><i>1450</i>&nbsp;			int nMeasurements = trainData.getNVars();</b>
<b class="nc"><i>1451</i>&nbsp;			int nClasses = trainData.getResponses().cols();</b>
<i>1452</i>&nbsp;			
<b class="nc"><i>1453</i>&nbsp;			var layers = new double[MAX_HIDDEN_LAYERS + 2];</b>
<b class="nc"><i>1454</i>&nbsp;			layers[0] = nMeasurements;</b>
<b class="nc"><i>1455</i>&nbsp;			int n = 1;</b>
<b class="nc"><i>1456</i>&nbsp;			for (int i = 1; i &lt;= MAX_HIDDEN_LAYERS; i++) {</b>
<b class="nc"><i>1457</i>&nbsp;				String name = &quot;hidden&quot; + i;</b>
<b class="nc"><i>1458</i>&nbsp;				if (!params.containsKey(name))</b>
<b class="nc"><i>1459</i>&nbsp;					continue;</b>
<b class="nc"><i>1460</i>&nbsp;				int size = params.getIntParameterValue(name);</b>
<i>1461</i>&nbsp;				// Every layer needs more than one neuron
<b class="nc"><i>1462</i>&nbsp;				if (size &gt; 1) {</b>
<b class="nc"><i>1463</i>&nbsp;					layers[n] = size;</b>
<b class="nc"><i>1464</i>&nbsp;					n++;</b>
<i>1465</i>&nbsp;				}
<i>1466</i>&nbsp;			}
<b class="nc"><i>1467</i>&nbsp;			layers[n] = nClasses;</b>
<b class="nc"><i>1468</i>&nbsp;			n++;</b>
<b class="nc"><i>1469</i>&nbsp;			if (n &lt; layers.length)</b>
<b class="nc"><i>1470</i>&nbsp;				layers = Arrays.copyOf(layers, n);</b>
<i>1471</i>&nbsp;			
<b class="nc"><i>1472</i>&nbsp;			var mat = new Mat(n, 1, opencv_core.CV_64F, Scalar.ZERO);</b>
<b class="nc"><i>1473</i>&nbsp;			DoubleIndexer idx = mat.createIndexer();</b>
<b class="nc"><i>1474</i>&nbsp;			for (int i = 0; i &lt; n; i++)</b>
<b class="nc"><i>1475</i>&nbsp;				idx.put(i, layers[i]);</b>
<b class="nc"><i>1476</i>&nbsp;			idx.release();</b>
<i>1477</i>&nbsp;			
<b class="nc"><i>1478</i>&nbsp;			model.setLayerSizes(mat);</b>
<i>1479</i>&nbsp;			
<i>1480</i>&nbsp;			// Set other parameters
<i>1481</i>&nbsp;//			var activation = (ActivationFunction)params.getChoiceParameterValue(&quot;activation&quot;);
<i>1482</i>&nbsp;//			double activationAlpha = params.getDoubleParameterValue(&quot;activationAlpha&quot;);
<i>1483</i>&nbsp;//			double activationBeta = params.getDoubleParameterValue(&quot;activationBeta&quot;);
<i>1484</i>&nbsp;//			model.setActivationFunction(activation.getActivationFunction(), activationAlpha, activationBeta);
<b class="nc"><i>1485</i>&nbsp;			model.setActivationFunction(ANN_MLP.SIGMOID_SYM, 1, 1);</b>
<i>1486</i>&nbsp;
<i>1487</i>&nbsp;//			var trainMethod = (TrainingMethod)params.getChoiceParameterValue(&quot;trainMethod&quot;);
<i>1488</i>&nbsp;//			double param1 = params.getDoubleParameterValue(&quot;trainParam1&quot;);
<i>1489</i>&nbsp;//			double param2 = params.getDoubleParameterValue(&quot;trainParam2&quot;);
<i>1490</i>&nbsp;//			model.setTrainMethod(trainMethod.getTrainingMethod(), param1, param2);
<i>1491</i>&nbsp;
<i>1492</i>&nbsp;			// Set termination criterion
<b class="nc"><i>1493</i>&nbsp;			model.setTermCriteria(updateTermCriteria(params, model.getTermCriteria()));</b>
<i>1494</i>&nbsp;			
<b class="nc"><i>1495</i>&nbsp;			logger.debug(&quot;Initializing ANN with layer sizes: &quot; + GeneralTools.arrayToString(Locale.getDefault(), layers, 0));</b>
<i>1496</i>&nbsp;		}
<i>1497</i>&nbsp;		
<i>1498</i>&nbsp;	}
<i>1499</i>&nbsp;	
<i>1500</i>&nbsp;	/**
<i>1501</i>&nbsp;	 * A multiclass version of ANN.
<i>1502</i>&nbsp;	 */
<b class="nc"><i>1503</i>&nbsp;	static class MulticlassANNClassifierCV extends ANNClassifierCV {</b>
<i>1504</i>&nbsp;		
<i>1505</i>&nbsp;		@Override
<i>1506</i>&nbsp;		public boolean supportsMulticlass() {
<b class="nc"><i>1507</i>&nbsp;			return true;</b>
<i>1508</i>&nbsp;		}
<i>1509</i>&nbsp;		
<i>1510</i>&nbsp;		@Override
<i>1511</i>&nbsp;		public String getName() {
<b class="nc"><i>1512</i>&nbsp;			return &quot;ANN MLP (Multiclass)&quot;;</b>
<i>1513</i>&nbsp;		}
<i>1514</i>&nbsp;		
<i>1515</i>&nbsp;	}
<i>1516</i>&nbsp;
<i>1517</i>&nbsp;}
</div>
</div>

<div class="footer">
    
    <div style="float:right;">generated on 2021-01-25 09:46</div>
</div>
</body>
</html>
