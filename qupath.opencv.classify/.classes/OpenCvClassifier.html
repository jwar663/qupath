


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html id="htmlId">
<head>
  <title>Coverage Report :: OpenCvClassifier</title>
  <style type="text/css">
    @import "../../.css/coverage.css";
  </style>
</head>

<body>
<div class="header"></div>

<div class="content">
<div class="breadCrumbs">
    [ <a href="../../index.html">all classes</a> ]
    [ <a href="../index.html">qupath.opencv.classify</a> ]
</div>

<h1>Coverage Summary for Class: OpenCvClassifier (qupath.opencv.classify)</h1>

<table class="coverageStats">
<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Class, %
</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
<tr>
  <td class="name">OpenCvClassifier</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 1)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 14)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 193)
  </span>
</td>
</tr>

</table>

<br/>
<br/>


<div class="sourceCode"><i>1</i>&nbsp;/*-
<i>2</i>&nbsp; * #%L
<i>3</i>&nbsp; * This file is part of QuPath.
<i>4</i>&nbsp; * %%
<i>5</i>&nbsp; * Copyright (C) 2014 - 2016 The Queen&#39;s University of Belfast, Northern Ireland
<i>6</i>&nbsp; * Contact: IP Management (ipmanagement@qub.ac.uk)
<i>7</i>&nbsp; * Copyright (C) 2018 - 2020 QuPath developers, The University of Edinburgh
<i>8</i>&nbsp; * %%
<i>9</i>&nbsp; * QuPath is free software: you can redistribute it and/or modify
<i>10</i>&nbsp; * it under the terms of the GNU General Public License as
<i>11</i>&nbsp; * published by the Free Software Foundation, either version 3 of the
<i>12</i>&nbsp; * License, or (at your option) any later version.
<i>13</i>&nbsp; * 
<i>14</i>&nbsp; * QuPath is distributed in the hope that it will be useful,
<i>15</i>&nbsp; * but WITHOUT ANY WARRANTY; without even the implied warranty of
<i>16</i>&nbsp; * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
<i>17</i>&nbsp; * GNU General Public License for more details.
<i>18</i>&nbsp; * 
<i>19</i>&nbsp; * You should have received a copy of the GNU General Public License 
<i>20</i>&nbsp; * along with QuPath.  If not, see &lt;https://www.gnu.org/licenses/&gt;.
<i>21</i>&nbsp; * #L%
<i>22</i>&nbsp; */
<i>23</i>&nbsp;
<i>24</i>&nbsp;package qupath.opencv.classify;
<i>25</i>&nbsp;
<i>26</i>&nbsp;import java.io.Externalizable;
<i>27</i>&nbsp;import java.io.IOException;
<i>28</i>&nbsp;import java.io.ObjectInput;
<i>29</i>&nbsp;import java.io.ObjectOutput;
<i>30</i>&nbsp;import java.nio.FloatBuffer;
<i>31</i>&nbsp;import java.nio.IntBuffer;
<i>32</i>&nbsp;import java.util.ArrayList;
<i>33</i>&nbsp;import java.util.Arrays;
<i>34</i>&nbsp;import java.util.Collection;
<i>35</i>&nbsp;import java.util.Collections;
<i>36</i>&nbsp;import java.util.HashMap;
<i>37</i>&nbsp;import java.util.Iterator;
<i>38</i>&nbsp;import java.util.LinkedHashMap;
<i>39</i>&nbsp;import java.util.List;
<i>40</i>&nbsp;import java.util.Map;
<i>41</i>&nbsp;
<i>42</i>&nbsp;import qupath.lib.analysis.stats.RunningStatistics;
<i>43</i>&nbsp;import qupath.lib.classifiers.Normalization;
<i>44</i>&nbsp;import qupath.lib.classifiers.PathObjectClassifier;
<i>45</i>&nbsp;import qupath.lib.measurements.MeasurementList;
<i>46</i>&nbsp;import qupath.lib.objects.PathObject;
<i>47</i>&nbsp;import qupath.lib.objects.classes.PathClass;
<i>48</i>&nbsp;import qupath.lib.objects.classes.PathClassFactory;
<i>49</i>&nbsp;import qupath.lib.plugins.parameters.ParameterList;
<i>50</i>&nbsp;import qupath.lib.plugins.parameters.Parameterizable;
<i>51</i>&nbsp;
<i>52</i>&nbsp;import static org.bytedeco.opencv.global.opencv_core.*;
<i>53</i>&nbsp;import static org.bytedeco.opencv.global.opencv_ml.*;
<i>54</i>&nbsp;
<i>55</i>&nbsp;import org.bytedeco.opencv.global.opencv_core;
<i>56</i>&nbsp;import org.bytedeco.opencv.opencv_core.*;
<i>57</i>&nbsp;import org.bytedeco.opencv.opencv_ml.*;
<i>58</i>&nbsp;
<i>59</i>&nbsp;import org.slf4j.Logger;
<i>60</i>&nbsp;import org.slf4j.LoggerFactory;
<i>61</i>&nbsp;
<i>62</i>&nbsp;/**
<i>63</i>&nbsp; * Abstract base class for OpenCV classifiers.
<i>64</i>&nbsp; * &lt;p&gt;
<i>65</i>&nbsp; * Note: We cannot directly serialize an OpenCV classifier, so instead the training data is serialized and the classifier
<i>66</i>&nbsp; * rebuilt as required.  This means that potentially if a classifier is reloaded with a different version of the OpenCV library,
<i>67</i>&nbsp; * if the training algorithm has changed then there may be a different result.
<i>68</i>&nbsp; * 
<i>69</i>&nbsp; * @author Pete Bankhead
<i>70</i>&nbsp; * @param &lt;T&gt; 
<i>71</i>&nbsp; *
<i>72</i>&nbsp; */
<i>73</i>&nbsp;public abstract class OpenCvClassifier&lt;T extends StatModel&gt; implements PathObjectClassifier, Externalizable {
<i>74</i>&nbsp;	
<i>75</i>&nbsp;	private static final long serialVersionUID = -7974734731360344083L;
<i>76</i>&nbsp;
<b class="nc"><i>77</i>&nbsp;	final private static Logger logger = LoggerFactory.getLogger(OpenCvClassifier.class);</b>
<i>78</i>&nbsp;	
<b class="nc"><i>79</i>&nbsp;	private long timestamp = System.currentTimeMillis();</b>
<b class="nc"><i>80</i>&nbsp;	private Normalization normalization = Normalization.NONE;</b>
<i>81</i>&nbsp;	List&lt;PathClass&gt; pathClasses;
<i>82</i>&nbsp;	private double[] normScale;
<i>83</i>&nbsp;	private double[] normOffset;
<i>84</i>&nbsp;	transient T classifier;
<i>85</i>&nbsp;	
<b class="nc"><i>86</i>&nbsp;	List&lt;String&gt; measurements = new ArrayList&lt;&gt;();</b>
<i>87</i>&nbsp;	// We can&#39;t serialize directly, so instead save all training data so classifier can be rebuilt as required
<b class="nc"><i>88</i>&nbsp;	float[] arrayTraining = null; // Array of training data</b>
<b class="nc"><i>89</i>&nbsp;	int[] arrayResponses = null; // Array of &#39;responses&#39;, i.e. indices to pathClasses list</b>
<i>90</i>&nbsp;	
<i>91</i>&nbsp;	
<i>92</i>&nbsp;	protected OpenCvClassifier() {}
<i>93</i>&nbsp;	
<i>94</i>&nbsp;
<i>95</i>&nbsp;	/**
<i>96</i>&nbsp;	 * Protected method used to indicate whether any options for the classifier have been changed.
<i>97</i>&nbsp;	 * If this false, then updateClassifier may choose not to retrain a classifier fully if it already has a classifier
<i>98</i>&nbsp;	 * trained on identical data.
<i>99</i>&nbsp;	 * 
<i>100</i>&nbsp;	 * By default this always returns false (assuming that no externally-accessible parameters are involved).
<i>101</i>&nbsp;	 * 
<i>102</i>&nbsp;	 * A conservative subclass that enables options to be set may always return &#39;true&#39; to force retraining in all instances.
<i>103</i>&nbsp;	 * 
<i>104</i>&nbsp;	 * A less conservative subclass that enables options to be set should check all options to see if they have changed since
<i>105</i>&nbsp;	 * the last time the classifier was trained, and return true or false accordingly.
<i>106</i>&nbsp;	 * 
<i>107</i>&nbsp;	 * @return
<i>108</i>&nbsp;	 */
<i>109</i>&nbsp;	protected boolean classifierOptionsChanged() {
<b class="nc"><i>110</i>&nbsp;		return false;</b>
<i>111</i>&nbsp;	}
<i>112</i>&nbsp;	
<i>113</i>&nbsp;	@Override
<i>114</i>&nbsp;	public boolean updateClassifier(final Map&lt;PathClass, List&lt;PathObject&gt;&gt; map, final List&lt;String&gt; measurements, Normalization normalization) {
<i>115</i>&nbsp;		
<i>116</i>&nbsp;		// There is a chance we don&#39;t need to retrain... to find out, cache the most important current variables
<b class="nc"><i>117</i>&nbsp;		boolean maybeSameClassifier = isValid() &amp;&amp; </b>
<i>118</i>&nbsp;				this.normalization == normalization &amp;&amp; 
<b class="nc"><i>119</i>&nbsp;				!classifierOptionsChanged() &amp;&amp; </b>
<b class="nc"><i>120</i>&nbsp;				this.measurements.equals(measurements) </b>
<b class="nc"><i>121</i>&nbsp;				&amp;&amp; pathClasses.size() == map.size() &amp;&amp; </b>
<b class="nc"><i>122</i>&nbsp;				map.keySet().containsAll(pathClasses);</b>
<i>123</i>&nbsp;		
<b class="nc"><i>124</i>&nbsp;		float[] arrayTrainingPrevious = arrayTraining;</b>
<b class="nc"><i>125</i>&nbsp;		int[] arrayResponsesPrevious = arrayResponses;</b>
<i>126</i>&nbsp;		
<b class="nc"><i>127</i>&nbsp;		pathClasses = new ArrayList&lt;&gt;(map.keySet());</b>
<b class="nc"><i>128</i>&nbsp;		Collections.sort(pathClasses);</b>
<i>129</i>&nbsp;
<b class="nc"><i>130</i>&nbsp;		int n = 0;</b>
<b class="nc"><i>131</i>&nbsp;		for (Map.Entry&lt;PathClass, List&lt;PathObject&gt;&gt; entry : map.entrySet()) {</b>
<b class="nc"><i>132</i>&nbsp;			n += entry.getValue().size();</b>
<b class="nc"><i>133</i>&nbsp;		}</b>
<i>134</i>&nbsp;
<i>135</i>&nbsp;		// Compute running statistics for normalization
<b class="nc"><i>136</i>&nbsp;		HashMap&lt;String, RunningStatistics&gt; statsMap = new LinkedHashMap&lt;&gt;();</b>
<b class="nc"><i>137</i>&nbsp;		for (String m : measurements)</b>
<b class="nc"><i>138</i>&nbsp;			statsMap.put(m, new RunningStatistics());</b>
<i>139</i>&nbsp;
<i>140</i>&nbsp;
<b class="nc"><i>141</i>&nbsp;		this.measurements.clear();</b>
<b class="nc"><i>142</i>&nbsp;		this.measurements.addAll(measurements);</b>
<b class="nc"><i>143</i>&nbsp;		int nMeasurements = measurements.size();</b>
<b class="nc"><i>144</i>&nbsp;		arrayTraining = new float[n * nMeasurements];</b>
<b class="nc"><i>145</i>&nbsp;		arrayResponses = new int[n];</b>
<i>146</i>&nbsp;
<b class="nc"><i>147</i>&nbsp;		int row = 0;</b>
<b class="nc"><i>148</i>&nbsp;		int nnan = 0;</b>
<b class="nc"><i>149</i>&nbsp;		for (PathClass pathClass : pathClasses) {</b>
<b class="nc"><i>150</i>&nbsp;			List&lt;PathObject&gt; list = map.get(pathClass);</b>
<b class="nc"><i>151</i>&nbsp;			int classIndex = pathClasses.indexOf(pathClass);</b>
<b class="nc"><i>152</i>&nbsp;			for (int i = 0; i &lt; list.size(); i++) {</b>
<b class="nc"><i>153</i>&nbsp;				MeasurementList measurementList = list.get(i).getMeasurementList();</b>
<b class="nc"><i>154</i>&nbsp;				int col = 0;</b>
<b class="nc"><i>155</i>&nbsp;				for (String m : measurements) {</b>
<b class="nc"><i>156</i>&nbsp;					double value = measurementList.getMeasurementValue(m);</b>
<b class="nc"><i>157</i>&nbsp;					if (Double.isNaN(value))</b>
<b class="nc"><i>158</i>&nbsp;						nnan++;</b>
<i>159</i>&nbsp;					else
<b class="nc"><i>160</i>&nbsp;						statsMap.get(m).addValue(value);</b>
<b class="nc"><i>161</i>&nbsp;					arrayTraining[row * nMeasurements + col] = (float)value;</b>
<b class="nc"><i>162</i>&nbsp;					col++;</b>
<b class="nc"><i>163</i>&nbsp;				}</b>
<b class="nc"><i>164</i>&nbsp;				arrayResponses[row] = classIndex;</b>
<b class="nc"><i>165</i>&nbsp;				row++;</b>
<i>166</i>&nbsp;			}
<b class="nc"><i>167</i>&nbsp;		}</b>
<i>168</i>&nbsp;		
<i>169</i>&nbsp;		
<i>170</i>&nbsp;		// Normalise, if required
<b class="nc"><i>171</i>&nbsp;		if (normalization != null &amp;&amp; normalization != Normalization.NONE) {</b>
<b class="nc"><i>172</i>&nbsp;			logger.debug(&quot;Training classifier with normalization: {}&quot;, normalization);</b>
<b class="nc"><i>173</i>&nbsp;			int numMeasurements = measurements.size();</b>
<b class="nc"><i>174</i>&nbsp;			normOffset = new double[numMeasurements];</b>
<b class="nc"><i>175</i>&nbsp;			normScale = new double[numMeasurements];</b>
<b class="nc"><i>176</i>&nbsp;			for (int i = 0; i &lt; numMeasurements; i++) {</b>
<b class="nc"><i>177</i>&nbsp;				RunningStatistics stats = statsMap.get(measurements.get(i));</b>
<b class="nc"><i>178</i>&nbsp;				if (normalization == Normalization.MEAN_VARIANCE) {</b>
<b class="nc"><i>179</i>&nbsp;					normOffset[i] = -stats.getMean();</b>
<b class="nc"><i>180</i>&nbsp;					if (stats.getStdDev() &gt; 0)</b>
<b class="nc"><i>181</i>&nbsp;						normScale[i] = 1.0 / stats.getStdDev();</b>
<b class="nc"><i>182</i>&nbsp;				} else if (normalization == Normalization.MIN_MAX){</b>
<b class="nc"><i>183</i>&nbsp;					normOffset[i] = -stats.getMin();</b>
<b class="nc"><i>184</i>&nbsp;					if (stats.getRange() &gt; 0)</b>
<b class="nc"><i>185</i>&nbsp;						normScale[i] = 1.0 / (stats.getMax() - stats.getMin());					</b>
<i>186</i>&nbsp;					else
<b class="nc"><i>187</i>&nbsp;						normScale[i] = 1.0;</b>
<i>188</i>&nbsp;				}
<i>189</i>&nbsp;			}
<i>190</i>&nbsp;			
<i>191</i>&nbsp;			// Apply normalisation
<b class="nc"><i>192</i>&nbsp;			for (int i = 0; i &lt; arrayTraining.length; i++) {</b>
<b class="nc"><i>193</i>&nbsp;				int k = i % numMeasurements;</b>
<b class="nc"><i>194</i>&nbsp;				arrayTraining[i] = (float)((arrayTraining[i] + normOffset[k]) * normScale[k]);</b>
<i>195</i>&nbsp;			}
<b class="nc"><i>196</i>&nbsp;			this.normalization = normalization;</b>
<i>197</i>&nbsp;			
<b class="nc"><i>198</i>&nbsp;		} else {</b>
<b class="nc"><i>199</i>&nbsp;			logger.debug(&quot;Training classifier without normalization&quot;);</b>
<b class="nc"><i>200</i>&nbsp;			normScale = null;</b>
<b class="nc"><i>201</i>&nbsp;			normOffset = null;</b>
<b class="nc"><i>202</i>&nbsp;			this.normalization = Normalization.NONE;</b>
<i>203</i>&nbsp;		}
<i>204</i>&nbsp;		
<i>205</i>&nbsp;		
<i>206</i>&nbsp;		
<i>207</i>&nbsp;		// Record that we have NaNs
<b class="nc"><i>208</i>&nbsp;		if (nnan &gt; 0)</b>
<b class="nc"><i>209</i>&nbsp;			logger.debug(&quot;Number of NaNs in training set: &quot; + nnan);</b>
<i>210</i>&nbsp;
<i>211</i>&nbsp;
<i>212</i>&nbsp;		
<i>213</i>&nbsp;		// Having got this far, check to see whether we really do need to retrain
<b class="nc"><i>214</i>&nbsp;		if (maybeSameClassifier) {</b>
<b class="nc"><i>215</i>&nbsp;			if (Arrays.equals(arrayTrainingPrevious, arrayTraining) &amp;&amp;</b>
<b class="nc"><i>216</i>&nbsp;					Arrays.equals(arrayResponsesPrevious, arrayResponses)) {</b>
<b class="nc"><i>217</i>&nbsp;				logger.info(&quot;Classifier already trained with the same samples - existing classifier will be used&quot;);</b>
<b class="nc"><i>218</i>&nbsp;				return false;</b>
<i>219</i>&nbsp;			}
<i>220</i>&nbsp;		}
<i>221</i>&nbsp;		
<i>222</i>&nbsp;		
<b class="nc"><i>223</i>&nbsp;		createAndTrainClassifier();</b>
<i>224</i>&nbsp;
<b class="nc"><i>225</i>&nbsp;		timestamp = System.currentTimeMillis();</b>
<b class="nc"><i>226</i>&nbsp;		this.measurements = new ArrayList&lt;&gt;(measurements);</b>
<i>227</i>&nbsp;		
<i>228</i>&nbsp;		
<b class="nc"><i>229</i>&nbsp;		return true;</b>
<i>230</i>&nbsp;	}
<i>231</i>&nbsp;	
<i>232</i>&nbsp;	
<i>233</i>&nbsp;	
<i>234</i>&nbsp;	protected void createAndTrainClassifier() {
<i>235</i>&nbsp;		
<i>236</i>&nbsp;		// Create the required Mats
<b class="nc"><i>237</i>&nbsp;		int nMeasurements = measurements.size();</b>
<i>238</i>&nbsp;		
<i>239</i>&nbsp;		
<b class="nc"><i>240</i>&nbsp;		Mat matTraining = new Mat(arrayTraining.length / nMeasurements, nMeasurements, CV_32FC1);</b>
<b class="nc"><i>241</i>&nbsp;		((FloatBuffer)matTraining.createBuffer()).put(arrayTraining);</b>
<b class="nc"><i>242</i>&nbsp;		Mat matResponses = new Mat(arrayResponses.length, 1, CV_32SC1);</b>
<b class="nc"><i>243</i>&nbsp;		((IntBuffer)matResponses.createBuffer()).put(arrayResponses);</b>
<i>244</i>&nbsp;		
<i>245</i>&nbsp;//		// Clear any existing classifier
<i>246</i>&nbsp;//		if (classifier != null)
<i>247</i>&nbsp;//			classifier.clear();
<i>248</i>&nbsp;		
<b class="nc"><i>249</i>&nbsp;		logger.info(&quot;Training size: &quot; + matTraining.size());</b>
<b class="nc"><i>250</i>&nbsp;		logger.info(&quot;Responses size: &quot; + matResponses.size());</b>
<i>251</i>&nbsp;		
<i>252</i>&nbsp;		// Create &amp; train the classifier
<i>253</i>&nbsp;		try {
<i>254</i>&nbsp;			// Some classifiers (e.g. RTrees) require the global RNG to be set before training.
<i>255</i>&nbsp;			// We can&#39;t trust OpenCV to be consistent in this between versions, so set it here -
<i>256</i>&nbsp;			// see https://github.com/qupath/qupath/issues/567
<i>257</i>&nbsp;			// Note: we set it before training so that createClassifier() could potentially override our setting.
<b class="nc"><i>258</i>&nbsp;			opencv_core.setRNGSeed(-1);</b>
<b class="nc"><i>259</i>&nbsp;			classifier = createClassifier();</b>
<b class="nc"><i>260</i>&nbsp;			classifier.train(matTraining, ROW_SAMPLE, matResponses);</b>
<b class="nc"><i>261</i>&nbsp;		} catch (Exception e) {</b>
<i>262</i>&nbsp;			// For reasons I haven&#39;t yet discerned, sometimes OpenCV throws an exception with the following message:
<i>263</i>&nbsp;			// OpenCV Error: Assertion failed ((int)_sleft.size() &lt; n &amp;&amp; (int)_sright.size() &lt; n) in calcDir, file /tmp/opencv320150620-1681-1u5iwhh/opencv-3.0.0/modules/ml/src/tree.cpp, line 1190
<i>264</i>&nbsp;			// With one sample fewer, it can often recover... so attempt that, rather than failing miserably...
<i>265</i>&nbsp;//			logger.error(&quot;Classifier training error&quot;, e);
<b class="nc"><i>266</i>&nbsp;			logger.info(&quot;Will attempt retraining classifier with one sample fewer...&quot;);</b>
<b class="nc"><i>267</i>&nbsp;			matTraining = matTraining.rowRange(0, matTraining.rows()-1);</b>
<b class="nc"><i>268</i>&nbsp;			matResponses = matResponses.rowRange(0, matResponses.rows()-1);</b>
<b class="nc"><i>269</i>&nbsp;			classifier = createClassifier();</b>
<b class="nc"><i>270</i>&nbsp;			classifier.train(matTraining, ROW_SAMPLE, matResponses);			</b>
<b class="nc"><i>271</i>&nbsp;		}</b>
<i>272</i>&nbsp;		
<b class="nc"><i>273</i>&nbsp;		matTraining.release();</b>
<b class="nc"><i>274</i>&nbsp;		matResponses.release();</b>
<i>275</i>&nbsp;		
<b class="nc"><i>276</i>&nbsp;		logger.info(&quot;Classifier trained with &quot; + arrayResponses.length + &quot; samples&quot;);</b>
<i>277</i>&nbsp;	}
<i>278</i>&nbsp;	
<i>279</i>&nbsp;
<i>280</i>&nbsp;	@Override
<i>281</i>&nbsp;	public List&lt;String&gt; getRequiredMeasurements() {
<b class="nc"><i>282</i>&nbsp;		return new ArrayList&lt;&gt;(measurements);</b>
<i>283</i>&nbsp;	}
<i>284</i>&nbsp;
<i>285</i>&nbsp;	@Override
<i>286</i>&nbsp;	public Collection&lt;PathClass&gt; getPathClasses() {
<b class="nc"><i>287</i>&nbsp;		return new ArrayList&lt;&gt;(pathClasses);</b>
<i>288</i>&nbsp;	}
<i>289</i>&nbsp;
<i>290</i>&nbsp;	@Override
<i>291</i>&nbsp;	public boolean isValid() {
<b class="nc"><i>292</i>&nbsp;		return classifier != null &amp;&amp; classifier.isTrained();</b>
<i>293</i>&nbsp;	}
<i>294</i>&nbsp;	
<i>295</i>&nbsp;	
<i>296</i>&nbsp;	@Override
<i>297</i>&nbsp;	public int classifyPathObjects(Collection&lt;PathObject&gt; pathObjects) {
<i>298</i>&nbsp;		
<i>299</i>&nbsp;		
<b class="nc"><i>300</i>&nbsp;		int counter = 0;</b>
<b class="nc"><i>301</i>&nbsp;		float[] array = new float[measurements.size()];</b>
<b class="nc"><i>302</i>&nbsp;		Mat samples = new Mat(1, array.length, CV_32FC1);</b>
<b class="nc"><i>303</i>&nbsp;		FloatBuffer bufferSamples = samples.createBuffer();</b>
<i>304</i>&nbsp;
<b class="nc"><i>305</i>&nbsp;		Mat results = new Mat();</b>
<i>306</i>&nbsp;
<b class="nc"><i>307</i>&nbsp;		for (PathObject pathObject : pathObjects) {</b>
<b class="nc"><i>308</i>&nbsp;			MeasurementList measurementList = pathObject.getMeasurementList();</b>
<b class="nc"><i>309</i>&nbsp;			int idx = 0;</b>
<b class="nc"><i>310</i>&nbsp;			for (String m : measurements) {</b>
<b class="nc"><i>311</i>&nbsp;				double value = measurementList.getMeasurementValue(m);</b>
<i>312</i>&nbsp;				
<b class="nc"><i>313</i>&nbsp;				if (normScale != null &amp;&amp; normOffset != null)</b>
<b class="nc"><i>314</i>&nbsp;					value = (value + normOffset[idx]) * normScale[idx];</b>
<i>315</i>&nbsp;				
<b class="nc"><i>316</i>&nbsp;				array[idx] = (float)value;</b>
<b class="nc"><i>317</i>&nbsp;				idx++;</b>
<b class="nc"><i>318</i>&nbsp;			}</b>
<i>319</i>&nbsp;			
<i>320</i>&nbsp;//			FloatIndexer indexerSamples = samples.createIndexer();
<i>321</i>&nbsp;//			indexerSamples.put(0L, 0L, array);
<b class="nc"><i>322</i>&nbsp;			bufferSamples.clear();</b>
<b class="nc"><i>323</i>&nbsp;			bufferSamples.put(array);</b>
<i>324</i>&nbsp;			
<i>325</i>&nbsp;			try {
<b class="nc"><i>326</i>&nbsp;				setPredictedClass(classifier, pathClasses, samples, results, pathObject);</b>
<i>327</i>&nbsp;//				float prediction = classifier.predict(samples);
<i>328</i>&nbsp;//				
<i>329</i>&nbsp;////				float prediction2 = classifier.predict(samples, results, StatModel.RAW_OUTPUT);
<i>330</i>&nbsp;//				float prediction2 = classifier.predict(samples, results, StatModel.RAW_OUTPUT);
<i>331</i>&nbsp;//				
<i>332</i>&nbsp;//				pathObject.setPathClass(pathClasses.get((int)prediction), prediction2);
<b class="nc"><i>333</i>&nbsp;				} catch (Exception e) {</b>
<b class="nc"><i>334</i>&nbsp;					pathObject.setPathClass(null);</b>
<b class="nc"><i>335</i>&nbsp;					logger.trace(&quot;Error with samples: {}&quot;, samples);</b>
<i>336</i>&nbsp;//					e.printStackTrace();
<b class="nc"><i>337</i>&nbsp;				}</b>
<i>338</i>&nbsp;			// TODO: See if this can be created outside the loop &amp; reused... appears to work, but docs say release should be called
<i>339</i>&nbsp;//			indexerSamples.release();
<i>340</i>&nbsp;//			}
<b class="nc"><i>341</i>&nbsp;			counter++;</b>
<b class="nc"><i>342</i>&nbsp;		}</b>
<i>343</i>&nbsp;		
<b class="nc"><i>344</i>&nbsp;		samples.release();</b>
<b class="nc"><i>345</i>&nbsp;		results.release();</b>
<i>346</i>&nbsp;				
<b class="nc"><i>347</i>&nbsp;		return counter;</b>
<i>348</i>&nbsp;	}
<i>349</i>&nbsp;	
<i>350</i>&nbsp;	
<i>351</i>&nbsp;	/**
<i>352</i>&nbsp;	 * Default prediction method.  Makes no attempt to populate results matrix or to provide probabilities.
<i>353</i>&nbsp;	 * (Results matrix only given as a parameter in case it is needed)
<i>354</i>&nbsp;	 * 
<i>355</i>&nbsp;	 * Subclasses may choose to override this method if they can do a better prediction, e.g. providing probabilities as well.
<i>356</i>&nbsp;	 * 
<i>357</i>&nbsp;	 * Upon returning, it is assumed that the PathClass of the PathObject will be correct, but it is not assumed that the results matrix will
<i>358</i>&nbsp;	 * have been updated.
<i>359</i>&nbsp;	 * 
<i>360</i>&nbsp;	 * @param classifier
<i>361</i>&nbsp;	 * @param pathClasses
<i>362</i>&nbsp;	 * @param samples
<i>363</i>&nbsp;	 * @param results
<i>364</i>&nbsp;	 * @param pathObject
<i>365</i>&nbsp;	 */
<i>366</i>&nbsp;	protected void setPredictedClass(final T classifier, final List&lt;PathClass&gt; pathClasses, final Mat samples, final Mat results, final PathObject pathObject) {
<b class="nc"><i>367</i>&nbsp;		float prediction = classifier.predict(samples);</b>
<b class="nc"><i>368</i>&nbsp;		PathClass pathClass = pathClasses.get((int)prediction);</b>
<b class="nc"><i>369</i>&nbsp;		pathObject.setPathClass(pathClass);</b>
<i>370</i>&nbsp;	}
<i>371</i>&nbsp;	
<i>372</i>&nbsp;	
<i>373</i>&nbsp;	/**
<i>374</i>&nbsp;	 * Create a new classifier, of whichever type the subclass desires.
<i>375</i>&nbsp;	 * 
<i>376</i>&nbsp;	 * It can be assumed that this is the classifier that will be used - without modifications - until createClassifier is called again.
<i>377</i>&nbsp;	 * 
<i>378</i>&nbsp;	 * In other words, it is permissible to cache values within createClassifier() (e.g. TermCriteria) that might
<i>379</i>&nbsp;	 * be import during prediction.
<i>380</i>&nbsp;	 * 
<i>381</i>&nbsp;	 * @return
<i>382</i>&nbsp;	 */
<i>383</i>&nbsp;	protected abstract T createClassifier();
<i>384</i>&nbsp;	
<i>385</i>&nbsp;	
<i>386</i>&nbsp;	
<i>387</i>&nbsp;
<i>388</i>&nbsp;//	@Override
<i>389</i>&nbsp;//	public int classifyPathObjects(Collection&lt;PathObject&gt; pathObjects) {
<i>390</i>&nbsp;//		
<i>391</i>&nbsp;//		
<i>392</i>&nbsp;//		int counter = 0;
<i>393</i>&nbsp;//		Mat samples = new Mat(1, measurements.size(), CvType.CV_32FC1);
<i>394</i>&nbsp;//		
<i>395</i>&nbsp;//		for (PathObject pathObject : pathObjects) {
<i>396</i>&nbsp;//			MeasurementList measurementList = pathObject.getMeasurementList();
<i>397</i>&nbsp;//			int idx = 0;
<i>398</i>&nbsp;//			for (String m : measurements) {
<i>399</i>&nbsp;//				double value = measurementList.getMeasurementValue(m);
<i>400</i>&nbsp;//				samples.put(0, idx, value);
<i>401</i>&nbsp;//				idx++;
<i>402</i>&nbsp;//			}
<i>403</i>&nbsp;//			
<i>404</i>&nbsp;//			float prediction = trees.predict(samples);
<i>405</i>&nbsp;//			
<i>406</i>&nbsp;////			if (computeProbabilities) {
<i>407</i>&nbsp;////				double prediction = svm.svm_predict_probability(model, nodes, probabilities);
<i>408</i>&nbsp;////				int index = (int)prediction;
<i>409</i>&nbsp;////				pathObject.setPathClass(pathClasses.get(index), probabilities[index]);
<i>410</i>&nbsp;////			} else {
<i>411</i>&nbsp;////				double prediction = svm.svm_predict(model, nodes);
<i>412</i>&nbsp;//				pathObject.setPathClass(pathClasses.get((int)prediction));
<i>413</i>&nbsp;////			}
<i>414</i>&nbsp;//			counter++;
<i>415</i>&nbsp;//		}
<i>416</i>&nbsp;//				
<i>417</i>&nbsp;//		return counter;
<i>418</i>&nbsp;//	}
<i>419</i>&nbsp;
<i>420</i>&nbsp;	
<i>421</i>&nbsp;	@Override
<i>422</i>&nbsp;	public String getDescription() {
<i>423</i>&nbsp;		
<b class="nc"><i>424</i>&nbsp;		if (classifier == null)</b>
<b class="nc"><i>425</i>&nbsp;			return &quot;No classifier set!&quot;;</b>
<i>426</i>&nbsp;		
<b class="nc"><i>427</i>&nbsp;		StringBuilder sb = new StringBuilder();</b>
<b class="nc"><i>428</i>&nbsp;		String mainString = getName() + (!isValid() ? &quot; (not trained)&quot; : &quot;&quot;);;</b>
<b class="nc"><i>429</i>&nbsp;		sb.append(&quot;Classifier:\t&quot;).append(mainString).append(&quot;\n\n&quot;);</b>
<b class="nc"><i>430</i>&nbsp;		sb.append(&quot;Classes:\t[&quot;);</b>
<b class="nc"><i>431</i>&nbsp;		Iterator&lt;PathClass&gt; iterClasses = getPathClasses().iterator();</b>
<b class="nc"><i>432</i>&nbsp;		while (iterClasses.hasNext()) {</b>
<b class="nc"><i>433</i>&nbsp;			sb.append(iterClasses.next());			</b>
<b class="nc"><i>434</i>&nbsp;			if (iterClasses.hasNext())</b>
<b class="nc"><i>435</i>&nbsp;				sb.append(&quot;, &quot;);</b>
<i>436</i>&nbsp;			else
<b class="nc"><i>437</i>&nbsp;				sb.append(&quot;]\n\n&quot;);</b>
<i>438</i>&nbsp;		}
<b class="nc"><i>439</i>&nbsp;		sb.append(&quot;Normalization:\t&quot;).append(normalization).append(&quot;\n\n&quot;);</b>
<i>440</i>&nbsp;		
<b class="nc"><i>441</i>&nbsp;		if (this instanceof Parameterizable) {</b>
<b class="nc"><i>442</i>&nbsp;			ParameterList params = ((Parameterizable)this).getParameterList();</b>
<b class="nc"><i>443</i>&nbsp;			String paramString = ParameterList.getParameterListJSON(params, &quot;\n  &quot;);</b>
<b class="nc"><i>444</i>&nbsp;			sb.append(&quot;Main parameters:\n  &quot;).append(paramString);</b>
<b class="nc"><i>445</i>&nbsp;			sb.append(&quot;\n\n&quot;);</b>
<i>446</i>&nbsp;		}
<i>447</i>&nbsp;		
<i>448</i>&nbsp;		
<b class="nc"><i>449</i>&nbsp;		List&lt;String&gt; measurements = getRequiredMeasurements();</b>
<b class="nc"><i>450</i>&nbsp;		sb.append(&quot;Required measurements (&quot;).append(measurements.size()).append(&quot;):\n&quot;);</b>
<b class="nc"><i>451</i>&nbsp;		Iterator&lt;String&gt; iter = getRequiredMeasurements().iterator();</b>
<b class="nc"><i>452</i>&nbsp;		while (iter.hasNext()) {</b>
<b class="nc"><i>453</i>&nbsp;			sb.append(&quot;    &quot;);</b>
<b class="nc"><i>454</i>&nbsp;			sb.append(iter.next());			</b>
<b class="nc"><i>455</i>&nbsp;			sb.append(&quot;\n&quot;);</b>
<i>456</i>&nbsp;		}
<i>457</i>&nbsp;		
<i>458</i>&nbsp;//		sb.append(&quot;\n&quot;);
<i>459</i>&nbsp;//		sb.append(classifier.toString());
<i>460</i>&nbsp;		
<b class="nc"><i>461</i>&nbsp;		return sb.toString();</b>
<i>462</i>&nbsp;//		return getName() + (!isValid() ? &quot; (not trained)&quot; : &quot;&quot;);
<i>463</i>&nbsp;	}
<i>464</i>&nbsp;	
<i>465</i>&nbsp;
<i>466</i>&nbsp;	@Override
<i>467</i>&nbsp;	public long getLastModifiedTimestamp() {
<b class="nc"><i>468</i>&nbsp;		return timestamp;</b>
<i>469</i>&nbsp;	}
<i>470</i>&nbsp;
<i>471</i>&nbsp;	
<i>472</i>&nbsp;	
<i>473</i>&nbsp;	
<i>474</i>&nbsp;	
<i>475</i>&nbsp;	@Override
<i>476</i>&nbsp;	public void writeExternal(ObjectOutput out) throws IOException {
<b class="nc"><i>477</i>&nbsp;		out.writeLong(2); // Version</b>
<b class="nc"><i>478</i>&nbsp;		out.writeLong(timestamp);</b>
<b class="nc"><i>479</i>&nbsp;		out.writeObject(pathClasses);</b>
<b class="nc"><i>480</i>&nbsp;		out.writeObject(normScale);</b>
<b class="nc"><i>481</i>&nbsp;		out.writeObject(normOffset);</b>
<b class="nc"><i>482</i>&nbsp;		out.writeObject(measurements);</b>
<b class="nc"><i>483</i>&nbsp;		out.writeObject(arrayTraining);</b>
<b class="nc"><i>484</i>&nbsp;		out.writeObject(arrayResponses);</b>
<b class="nc"><i>485</i>&nbsp;		out.writeObject(normalization.toString());</b>
<i>486</i>&nbsp;	}
<i>487</i>&nbsp;
<i>488</i>&nbsp;
<i>489</i>&nbsp;	@SuppressWarnings(&quot;unchecked&quot;)
<i>490</i>&nbsp;	@Override
<i>491</i>&nbsp;	public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException {
<i>492</i>&nbsp;		
<b class="nc"><i>493</i>&nbsp;		long version = in.readLong();</b>
<b class="nc"><i>494</i>&nbsp;		if (version &lt; 1 || version &gt; 2)</b>
<b class="nc"><i>495</i>&nbsp;			throw new IOException(&quot;Unsupported version!&quot;);</b>
<i>496</i>&nbsp;		
<b class="nc"><i>497</i>&nbsp;		timestamp = in.readLong();</b>
<b class="nc"><i>498</i>&nbsp;		pathClasses = (List&lt;PathClass&gt;)in.readObject();</b>
<i>499</i>&nbsp;		// Ensure we have correct, single entries
<b class="nc"><i>500</i>&nbsp;		if (pathClasses != null) {</b>
<b class="nc"><i>501</i>&nbsp;			for (int i = 0; i &lt; pathClasses.size(); i++) {</b>
<b class="nc"><i>502</i>&nbsp;				pathClasses.set(i, PathClassFactory.getSingletonPathClass(pathClasses.get(i)));</b>
<i>503</i>&nbsp;			}
<i>504</i>&nbsp;		}
<i>505</i>&nbsp;		
<b class="nc"><i>506</i>&nbsp;		normScale = (double[])in.readObject();</b>
<b class="nc"><i>507</i>&nbsp;		normOffset = (double[])in.readObject();</b>
<b class="nc"><i>508</i>&nbsp;		measurements = (List&lt;String&gt;)in.readObject();</b>
<b class="nc"><i>509</i>&nbsp;		arrayTraining = (float[])in.readObject();</b>
<b class="nc"><i>510</i>&nbsp;		arrayResponses = (int[])in.readObject();</b>
<b class="nc"><i>511</i>&nbsp;		if (version == 2) {</b>
<b class="nc"><i>512</i>&nbsp;			String method = (String)in.readObject();</b>
<b class="nc"><i>513</i>&nbsp;			for (Normalization n : Normalization.values()) {</b>
<b class="nc"><i>514</i>&nbsp;				if (n.toString().equals(method)) {</b>
<b class="nc"><i>515</i>&nbsp;					normalization = n;</b>
<b class="nc"><i>516</i>&nbsp;					break;</b>
<i>517</i>&nbsp;				}
<i>518</i>&nbsp;			}
<i>519</i>&nbsp;//			normalization = Normalization.valueOf((String)in.readObject());
<i>520</i>&nbsp;		}
<i>521</i>&nbsp;		
<b class="nc"><i>522</i>&nbsp;		if (arrayTraining != null &amp;&amp; arrayResponses != null) {</b>
<b class="nc"><i>523</i>&nbsp;			createAndTrainClassifier();</b>
<i>524</i>&nbsp;		}
<i>525</i>&nbsp;		
<i>526</i>&nbsp;	}
<i>527</i>&nbsp;
<i>528</i>&nbsp;	
<i>529</i>&nbsp;	
<i>530</i>&nbsp;	
<i>531</i>&nbsp;
<i>532</i>&nbsp;}
</div>
</div>

<div class="footer">
    
    <div style="float:right;">generated on 2021-01-25 09:46</div>
</div>
</body>
</html>
